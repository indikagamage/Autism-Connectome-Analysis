{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline\n",
    "1. Create a BIDSDataGrabber Node to read data files\n",
    "2. Create a IdentityInterface Node to iterate over multiple Subjects\n",
    "3. Create following Nodes for preprocessing: (Based on [Nan-kuei Chen's resting state analysis pipeline:](https://wiki.biac.duke.edu/biac:analysis:resting_pipeline)\n",
    "    - [-] convert data to nii in LAS orientation (Skip if NYU is already in [LAS Orientation](http://www.grahamwideman.com/gw/brain/orientation/orientterms.htm))\n",
    "    - [x] Exclude 4 volumes from the functional scan \n",
    "    - [x] slice time correction\n",
    "    - [x] motion correction, {[then regress out motion parameter] - This will be done later}\n",
    "    - [x] Skull stripping and mask generation using mean of functional scan got using mcflirt\n",
    "    - [x] Apply mask to Functional image\n",
    "    - [x] Co-Registration with Anatomical Image\n",
    "    - [x] normalize functional data\n",
    "    - [-] regress out WM/CSF\n",
    "    - [] bandpass filter\n",
    "    \n",
    "4. Embed them into a workflow\n",
    "5. Do the Preprocessing of 3 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bids.grabbids import BIDSLayout\n",
    "from nipype.interfaces.fsl import (BET, ExtractROI, FAST, FLIRT, ImageMaths,\n",
    "                                   MCFLIRT, SliceTimer, Threshold,Info)\n",
    "from nipype.interfaces.afni import Resample\n",
    "from nipype.interfaces.io import DataSink\n",
    "from nipype.pipeline import Node, MapNode, Workflow\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from nipype.interfaces import afni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "path_cwd = os.getcwd()\n",
    "path_split_list = path_cwd.split('/')\n",
    "s = path_split_list[0:-1]\n",
    "s = opj('/',*s) # *s converts list to path, # very important to add '/' in the begining so it is read as directory later\n",
    "base_directory = opj(s,'result') \n",
    "parent_wf_directory = 'preprocessPipeline'\n",
    "child_wf_directory = 'coregistrationPipeline'\n",
    "\n",
    "data_directory = opj(s,\"data/ABIDE-BIDS/NYU/\")\n",
    "\n",
    "# mask_file = '/media/varun/LENOVO4/Projects/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050952/skullStrip/sub-0050952_T1w_resample_brain_mask.nii.gz'\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/preprocess/result'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_directory # result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_subjects = 2 # Number of subjects you wish to preprocess\n",
    "\n",
    "# base_directory = '/home/jovyan/work/preprocess/result'\n",
    "# parent_wf_directory = 'preprocessPipeline'\n",
    "# child_wf_directory = 'coregistrationPipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout = BIDSLayout(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Data directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/\r\n",
      "├── participants.tsv\r\n",
      "├── sub-0050952\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050952_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050952_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050953\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050953_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050953_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050954\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050954_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050954_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050955\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050955_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050955_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050956\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050956_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050956_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050957\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050957_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050957_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050958\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050958_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050958_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050959\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050959_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050959_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050960\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050960_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050960_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050961\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050961_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050961_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050962\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050962_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050962_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050964\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050964_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050964_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050965\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050965_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050965_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050966\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050966_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050966_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050967\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050967_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050967_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050968\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050968_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050968_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050969\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050969_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050969_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050970\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050970_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050970_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050971\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050971_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050971_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050972\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050972_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050972_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050973\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050973_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050973_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050974\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050974_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050974_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050975\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050975_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050975_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050976\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050976_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050976_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050977\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050977_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050977_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050978\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050978_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050978_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050979\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050979_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050979_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050980\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050980_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050980_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050981\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050981_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050981_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050982\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050982_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050982_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050983\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050983_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050983_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050984\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050984_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050984_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050985\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050985_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050985_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050986\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050986_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050986_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050987\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050987_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050987_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050988\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050988_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050988_task-rest_run-1_bold.nii.gz\r\n",
      "├── sub-0050989\r\n",
      "│   ├── anat\r\n",
      "│   │   └── sub-0050989_T1w.nii.gz\r\n",
      "│   └── func\r\n",
      "│       └── sub-0050989_task-rest_run-1_bold.nii.gz\r\n",
      "├── T1w.json\r\n",
      "└── task-rest_bold.json\r\n",
      "\r\n",
      "111 directories, 77 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree /home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout.get_subjects(); # working!Gives us list of all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the metadata associated with a subject. [Takes as argumment the filename of subject ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_subject = opj(data_directory,'sub-0050954/func/sub-0050952_task-rest_run-1_bold.nii.gz')\n",
    "metadata = layout.get_metadata(path=path_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the Repetition Time (of fMRI) of the subject whose metadata was extracted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TR  = metadata['RepetitionTime']\n",
    "metadata; # just add or remove the semicolon to supress or see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a better way to extract the TR of an experiment of fMRI.  \n",
    "In BIDS format there is one json file associated with the data set that contains the details of the data acquisition. Here we have -> ```task-rest_bold.json```. Let's extract the TR from this file.  \n",
    "Similarly there is a json file associated with the anatomical scan as well. Here - ```T1w.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_path = opj(data_directory,'task-rest_bold.json')\n",
    "with open(json_path, 'rt') as fp:\n",
    "    task_info = json.load(fp)\n",
    "#TR = task_info['RepetitionTime']\n",
    "task_info;\n",
    "# 'rt' means that you want to open the file in read mode and text mode(not sure what text mode is) \n",
    "# Also -> with open() as ... is just a fancy way of reading file that makes sure that the file object\n",
    "# is destroyed automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can extract the TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TR = task_info['RepetitionTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number_of_subjects = 1\n",
    "\n",
    "subject_list = (layout.get_subjects())[0:number_of_subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our own custom function - BIDSDataGrabber using a Function Interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nifti_filenames(subject_id,data_dir):\n",
    "#     Remember that all the necesary imports need to be INSIDE the function for the Function Interface to work!\n",
    "    from bids.grabbids import BIDSLayout\n",
    "    \n",
    "    layout = BIDSLayout(data_dir)\n",
    "    \n",
    "    anat_file_path = [f.filename for f in layout.get(subject=subject_id, type='T1w', extensions=['nii', 'nii.gz'])]\n",
    "    func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])]\n",
    "    \n",
    "    return anat_file_path[0],func_file_path[0]\n",
    "\n",
    "# Refer to Supplementary material section One for info on arguments for layout.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap it inside a Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BIDSDataGrabber = Node(Function(function=get_nifti_filenames, input_names=['subject_id','data_dir'],\n",
    "                                output_names=['anat_file_path','func_file_path']), name='BIDSDataGrabber')\n",
    "BIDSDataGrabber.iterables = [('subject_id',subject_list)]\n",
    "BIDSDataGrabber.inputs.data_dir = data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To test the function wrapped in the node\n",
    "\n",
    "# BIDSDataGrabber.inputs.data_dir = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/'\n",
    "# BIDSDataGrabber.inputs.subject_id = '0050954'\n",
    "# res = BIDSDataGrabber.run()\n",
    "\n",
    "# res.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Skipping 4 starting scans\n",
    "Extract ROI for skipping first 4 scans of the functional data \n",
    "> **Arguments:**  \n",
    "t_min: (corresponds to time dimension) Denotes the starting time of the inclusion  \n",
    "t_size: Denotes the number of scans to include\n",
    "\n",
    "The logic behind skipping 4 initial scans is to take scans after the subject has stabalized in the scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtractROI - skip dummy scans\n",
    "extract = Node(ExtractROI(t_min=4, t_size=-1),\n",
    "               output_type='NIFTI',\n",
    "               name=\"extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice time correction\n",
    "Created a Node that does slice time correction\n",
    "> **Arguments**:  \n",
    "index_dir=False -> Slices were taken bottom to top i.e. in ascending order  \n",
    "interleaved=True means odd slices were acquired first and then even slices [or vice versa(Not sure)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slicetimer = Node(SliceTimer(index_dir=False,\n",
    "                             interleaved=True,\n",
    "                             output_type='NIFTI',\n",
    "                             time_repetition=TR),\n",
    "                  name=\"slicetimer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To test Slicetimer\n",
    "# slicetimer.inputs.in_file = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz'\n",
    "# res = slicetimer.run()\n",
    "# res.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction\n",
    "Motion correction is done using fsl's mcflirt. It alligns all the volumes of a functional scan to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MCFLIRT - motion correction\n",
    "mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                       save_plots=True,\n",
    "                       output_type='NIFTI'),\n",
    "               name=\"mcflirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To test mcflirt\n",
    "# mcflirt.inputs.in_file = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz'\n",
    "# res_mcflirt = mcflirt.run()\n",
    "# res_mcflirt.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skull striping\n",
    "I used fsl's BET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import BET #,ExtractROI can be imported to ignore some brain volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skullStrip = Node(BET(mask=True),name='skullStrip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: Do not include special characters in ```name``` field above coz then  wf.writegraph will cause issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BET.help(); # Useful to see what are the parameters taken by BET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Mask to functional data\n",
    "Mean file of the motion corrected functional scan is sent to skullStrip to get just the brain and the mask_image. Mask_image is just a binary file (containing 1 where brain is present and 0 where it isn't).    \n",
    "After getting the mask_image form skullStrip, apply that mask to aligned functional image to extract its brain and remove the skull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function\n",
    "# in_file: The file on which you want to apply mask\n",
    "# mask_file:  The mask you want to use. Make sure that mask_file has same size as in_file\n",
    "# out_file : Result of applying mask in in_file -> Gives the path of the output file\n",
    "\n",
    "def applyMask_func(in_file, mask_file):\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    from os.path import join as opj\n",
    "\n",
    "    # convert from unicode to string : u'/tmp/tmp8daO2Q/..' -> '/tmp/tmp8daO2Q/..' i.e. removes the prefix 'u'\n",
    "    mask_file = str(mask_file)\n",
    "\n",
    "    brain_data = nib.load(in_file)\n",
    "    mask_data = nib.load(mask_file)\n",
    "\n",
    "    brain = brain_data.get_data()\n",
    "    mask = mask_data.get_data()\n",
    "    \n",
    "    # applying mask by multiplying elementwise to the binary mask\n",
    "\n",
    "    if len(brain.shape) == 3: # Anat file\n",
    "        brain = np.multiply(brain,mask)\n",
    "    elif len(brain.shape) > 3: # Functional File\n",
    "        for t in range(brain.shape[-1]):\n",
    "            brain[:,:,:,t] = np.multiply(brain[:,:,:,t],mask)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Saving the brain file\n",
    "    \n",
    "#     # paths ------------------------------------- \n",
    "    path = os.getcwd()\n",
    "#     print (\"################# Current Working Directory is ################: \",path)\n",
    "#     path_split_list = path.split('/')\n",
    "#     s = path_split_list[0:-1]\n",
    "#     s = opj(*s) # *s converts list to path\n",
    "#     base_directory = opj(s,'result')\n",
    "#     parent_wf_directory = 'preprocessPipeline'\n",
    "#     child_wf_directory = 'coregistrationPipeline'\n",
    "#     #---------------------------------------------\n",
    "#     Not Needed. I found out that whenever a node is being executed, it becomes the current directory and whatever you create, will be stored here.\n",
    "    \n",
    "#     mask_file_split_list = mask_file.split('/')\n",
    "#     mask_file_name = mask_file_split_list[-1]\n",
    "    \n",
    "    in_file_split_list = in_file.split('/')\n",
    "    in_file_name = in_file_split_list[-1]\n",
    "#     in_file_subject_name = in_file_split_list[-3]\n",
    "    \n",
    "#     from IPython.core.debugger import Tracer; Tracer()()    # Debugger doesnt work in nipype\n",
    "#     print (\"base_directory \",base_directory)\n",
    "#     print ('parent_wf_directory ', parent_wf_directory)\n",
    "#     print ('child_wf_directory ',child_wf_directory)\n",
    "#     print ('in_file_subject_name ',in_file_subject_name )\n",
    "#     print ('out_file ' ,out_file)\n",
    "    \n",
    "    out_file = in_file_name + '_brain.nii.gz' # changing name\n",
    "    print (\"The name of the file Outputted is \",out_file)\n",
    "#     out_file = opj(base_directory, parent_wf_directory, child_wf_directory, in_file_subject_name, 'applyMask', out_file) # prefixing the saving location\n",
    "    \n",
    "    print (\"The name of the final file path  outputted is \",out_file)\n",
    "    brain_with_header = nib.Nifti1Image(brain, affine=brain_data.affine,header = brain_data.header)\n",
    "    nib.save(brain_with_header,out_file)\n",
    "    \n",
    "    out_file = opj(path,out_file)\n",
    "    \n",
    "    return out_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# home/jovyan/work/preprocess/result/\n",
    "# preprocessPipeline/coregistrationPipeline/\n",
    "# _subject_id_0050952/result/preprocessPipeline/\n",
    "# coregistrationPipeline/applyMask/\n",
    "# sub-0050952_T1w_resample_brain_mask.nii.gz_brain.nii.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from os.path import join as opj\n",
    "# opj(base_directory, parent_wf_folder, child_wf_folder, '_hekko.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the above function inside a Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applyMask = Node(Function(function=applyMask_func, input_names=['in_file','mask_file'],\n",
    "                                output_names=['out_file']), name='applyMask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an IdentityInterface node to Distribute the subjects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an IdentityInterface Node that helps us to iterate over all the subjects. In this type of node the inputs = outputs that's why its called an identity node. It has an aditional feature that it can iterate over the values a single field can take. In our case we tell it to iterate over field '`subject_id`' and take values given by `subject_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_directory ->'/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nipype import IdentityInterface\n",
    "# infosource = Node(IdentityInterface(fields=['subject_id','data_dir']),\n",
    "#                   name=\"infosource\")\n",
    "# infosource.inputs.data_dir = data_directory \n",
    "# infosource.iterables = [('subject_id', subject_list)]\n",
    "# # Note: Field 'data_dir' stays constant while the field'subject_id' takes on various values \n",
    "# #       as there are multiple subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infosource.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infosource.outputs # Checking the outputs of the above created node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resample - resample anatomy to 2x2x2 voxel resolution\n",
    "resample = Node(Resample(voxel_size=(2, 2, 2), resample_mode='Cu',\n",
    "                         outputtype='NIFTI'),\n",
    "                name=\"resample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **3dresample**\n",
      "\n",
      "Resample or reorient an image using AFNI 3dresample command\n",
      "\n",
      "For complete details, see the `3dresample Documentation.\n",
      "<https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dresample.html>`_\n",
      "\n",
      "Examples\n",
      "========\n",
      "\n",
      ">>> from nipype.interfaces import afni\n",
      ">>> resample = afni.Resample()\n",
      ">>> resample.inputs.in_file = 'functional.nii'\n",
      ">>> resample.inputs.orientation= 'RPI'\n",
      ">>> resample.inputs.outputtype = 'NIFTI'\n",
      ">>> resample.cmdline  # doctest: +ALLOW_UNICODE\n",
      "'3dresample -orient RPI -prefix functional_resample.nii -inset functional.nii'\n",
      ">>> res = resample.run()  # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\tinput file to 3dresample\n",
      "\t\tflag: -inset %s, position: -1\n",
      "\n",
      "\t[Optional]\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tenviron: (a dictionary with keys which are a newbytes or None or a\n",
      "\t\t newstr or None and with values which are a newbytes or None or a\n",
      "\t\t newstr or None, nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tmaster: (a file name)\n",
      "\t\talign dataset grid to a reference file\n",
      "\t\tflag: -master %s\n",
      "\torientation: (a unicode string)\n",
      "\t\tnew orientation code\n",
      "\t\tflag: -orient %s\n",
      "\tout_file: (a file name)\n",
      "\t\toutput image file name\n",
      "\t\tflag: -prefix %s\n",
      "\toutputtype: (u'NIFTI_GZ' or u'AFNI' or u'NIFTI')\n",
      "\t\tAFNI output filetype\n",
      "\tresample_mode: (u'NN' or u'Li' or u'Cu' or u'Bk')\n",
      "\t\tresampling method from set {\"NN\", \"Li\", \"Cu\", \"Bk\"}. These are for\n",
      "\t\t\"Nearest Neighbor\", \"Linear\", \"Cubic\" and \"Blocky\"interpolation,\n",
      "\t\trespectively. Default is NN.\n",
      "\t\tflag: -rmode %s\n",
      "\tterminal_output: (u'stream' or u'allatonce' or u'file' or u'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\tvoxel_size: (a tuple of the form: (a float, a float, a float))\n",
      "\t\tresample to new dx, dy and dz\n",
      "\t\tflag: -dxyz %f %f %f\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\toutput file\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Resample.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "out_file = <undefined>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DataSink object\n",
    "dataSink = Node(DataSink(), name='datasink')\n",
    "\n",
    "# Name of the output folder\n",
    "dataSink.inputs.base_directory = 'dataSink'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python2/lib/python2.7/site-packages/nipype-0.13.0rc1-py2.7.egg/nipype/interfaces/base.py:431: UserWarning: Input apply_xfm requires inputs: in_matrix_file\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Node for getting the xformation matrix \n",
    "coreg_step1 = Node(FLIRT(output_type='NIFTI'), name=\"coreg_step1\")\n",
    "\n",
    "# Node for applying xformation matrix to functional data\n",
    "coreg_step2 = Node(FLIRT(output_type='NIFTI',\n",
    "                         apply_xfm=True), name=\"coreg_step2\")\n",
    "\n",
    "\n",
    "# Node for Normalizing/Standardizing the anatomical and getting the xformation matrix\n",
    "coreg_step1_Normalize = Node(FLIRT(reference='/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz',\n",
    "                         output_type='NIFTI'), name=\"coreg_step1_Normalize\")\n",
    "\n",
    "# Extra masking of 2mm anat file based on MNI mask coz it was a bit dialated\n",
    "coreg_step1_Normalize_masking = Node(Function(function=applyMask_func, input_names=['in_file','mask_file'],\n",
    "                                output_names=['out_file']), name=\"coreg_step1_Normalize_masking\")\n",
    "\n",
    "\n",
    "#Node for applying the xformation matirix to functional data\n",
    "\n",
    "coreg_step2_Normalize = Node(FLIRT(reference='/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz',\n",
    "                         output_type='NIFTI', apply_xfm=True), name=\"coreg_step2_Normalize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNI152_2mm_mask = Node(IdentityInterface(fields=['mask_file']),\n",
    "                  name=\"MNI152_2mm_mask\")\n",
    "\n",
    "MNI152_2mm_mask.inputs.mask_file = '/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain_mask.nii.gz'\n",
    "\n",
    "# MNI152_2mm_mask.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNI152_2mm_mask.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observed using fslsyes that the brain is enlarged if you Normalize a  brain resampled to 2mm brain. This in turn causes the functional data to enlarge as well after normalization. So, I will apply MNI152_2mm brain mask to the  resample brain after it has been normalized.\n",
    "\n",
    "For that let's first create a Node that applies the  MNI152_2mm brain mast to the Output of Coreg_step1_Normalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **flirt**\n",
      "\n",
      "Use FSL FLIRT for coregistration.\n",
      "\n",
      "For complete details, see the `FLIRT Documentation.\n",
      "<http://www.fmrib.ox.ac.uk/fsl/flirt/index.html>`_\n",
      "\n",
      "To print out the command line help, use:\n",
      "    fsl.FLIRT().inputs_help()\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> from nipype.testing import example_data\n",
      ">>> flt = fsl.FLIRT(bins=640, cost_func='mutualinfo')\n",
      ">>> flt.inputs.in_file = 'structural.nii'\n",
      ">>> flt.inputs.reference = 'mni.nii'\n",
      ">>> flt.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> flt.cmdline # doctest: +ELLIPSIS +ALLOW_UNICODE\n",
      "'flirt -in structural.nii -ref mni.nii -out structural_flirt.nii.gz -omat structural_flirt.mat -bins 640 -searchcost mutualinfo'\n",
      ">>> res = flt.run() #doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\tinput file\n",
      "\t\tflag: -in %s, position: 0\n",
      "\treference: (an existing file name)\n",
      "\t\treference file\n",
      "\t\tflag: -ref %s, position: 1\n",
      "\n",
      "\t[Optional]\n",
      "\tangle_rep: (u'quaternion' or u'euler')\n",
      "\t\trepresentation of rotation angles\n",
      "\t\tflag: -anglerep %s\n",
      "\tapply_isoxfm: (a float)\n",
      "\t\tas applyxfm but forces isotropic resampling\n",
      "\t\tflag: -applyisoxfm %f\n",
      "\t\tmutually_exclusive: apply_xfm\n",
      "\tapply_xfm: (a boolean)\n",
      "\t\tapply transformation supplied by in_matrix_file\n",
      "\t\tflag: -applyxfm\n",
      "\t\trequires: in_matrix_file\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tbbrslope: (a float)\n",
      "\t\tvalue of bbr slope\n",
      "\t\tflag: -bbrslope %f\n",
      "\tbbrtype: (u'signed' or u'global_abs' or u'local_abs')\n",
      "\t\ttype of bbr cost function: signed [default], global_abs, local_abs\n",
      "\t\tflag: -bbrtype %s\n",
      "\tbgvalue: (a float)\n",
      "\t\tuse specified background value for points outside FOV\n",
      "\t\tflag: -setbackground %f\n",
      "\tbins: (an integer (int or long))\n",
      "\t\tnumber of histogram bins\n",
      "\t\tflag: -bins %d\n",
      "\tcoarse_search: (an integer (int or long))\n",
      "\t\tcoarse search delta angle\n",
      "\t\tflag: -coarsesearch %d\n",
      "\tcost: (u'mutualinfo' or u'corratio' or u'normcorr' or u'normmi' or\n",
      "\t\t u'leastsq' or u'labeldiff' or u'bbr')\n",
      "\t\tcost function\n",
      "\t\tflag: -cost %s\n",
      "\tcost_func: (u'mutualinfo' or u'corratio' or u'normcorr' or u'normmi'\n",
      "\t\t or u'leastsq' or u'labeldiff' or u'bbr')\n",
      "\t\tcost function\n",
      "\t\tflag: -searchcost %s\n",
      "\tdatatype: (u'char' or u'short' or u'int' or u'float' or u'double')\n",
      "\t\tforce output data type\n",
      "\t\tflag: -datatype %s\n",
      "\tdisplay_init: (a boolean)\n",
      "\t\tdisplay initial matrix\n",
      "\t\tflag: -displayinit\n",
      "\tdof: (an integer (int or long))\n",
      "\t\tnumber of transform degrees of freedom\n",
      "\t\tflag: -dof %d\n",
      "\techospacing: (a float)\n",
      "\t\tvalue of EPI echo spacing - units of seconds\n",
      "\t\tflag: -echospacing %f\n",
      "\tenviron: (a dictionary with keys which are a newbytes or None or a\n",
      "\t\t newstr or None and with values which are a newbytes or None or a\n",
      "\t\t newstr or None, nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tfieldmap: (a file name)\n",
      "\t\tfieldmap image in rads/s - must be already registered to the\n",
      "\t\treference image\n",
      "\t\tflag: -fieldmap %s\n",
      "\tfieldmapmask: (a file name)\n",
      "\t\tmask for fieldmap image\n",
      "\t\tflag: -fieldmapmask %s\n",
      "\tfine_search: (an integer (int or long))\n",
      "\t\tfine search delta angle\n",
      "\t\tflag: -finesearch %d\n",
      "\tforce_scaling: (a boolean)\n",
      "\t\tforce rescaling even for low-res images\n",
      "\t\tflag: -forcescaling\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tin_matrix_file: (a file name)\n",
      "\t\tinput 4x4 affine matrix\n",
      "\t\tflag: -init %s\n",
      "\tin_weight: (an existing file name)\n",
      "\t\tFile for input weighting volume\n",
      "\t\tflag: -inweight %s\n",
      "\tinterp: (u'trilinear' or u'nearestneighbour' or u'sinc' or u'spline')\n",
      "\t\tfinal interpolation method used in reslicing\n",
      "\t\tflag: -interp %s\n",
      "\tmin_sampling: (a float)\n",
      "\t\tset minimum voxel dimension for sampling\n",
      "\t\tflag: -minsampling %f\n",
      "\tno_clamp: (a boolean)\n",
      "\t\tdo not use intensity clamping\n",
      "\t\tflag: -noclamp\n",
      "\tno_resample: (a boolean)\n",
      "\t\tdo not change input sampling\n",
      "\t\tflag: -noresample\n",
      "\tno_resample_blur: (a boolean)\n",
      "\t\tdo not use blurring on downsampling\n",
      "\t\tflag: -noresampblur\n",
      "\tno_search: (a boolean)\n",
      "\t\tset all angular searches to ranges 0 to 0\n",
      "\t\tflag: -nosearch\n",
      "\tout_file: (a file name)\n",
      "\t\tregistered output file\n",
      "\t\tflag: -out %s, position: 2\n",
      "\tout_log: (a file name)\n",
      "\t\toutput log\n",
      "\t\trequires: save_log\n",
      "\tout_matrix_file: (a file name)\n",
      "\t\toutput affine matrix in 4x4 asciii format\n",
      "\t\tflag: -omat %s, position: 3\n",
      "\toutput_type: (u'NIFTI_PAIR' or u'NIFTI_PAIR_GZ' or u'NIFTI_GZ' or\n",
      "\t\t u'NIFTI')\n",
      "\t\tFSL output type\n",
      "\tpadding_size: (an integer (int or long))\n",
      "\t\tfor applyxfm: interpolates outside image by size\n",
      "\t\tflag: -paddingsize %d\n",
      "\tpedir: (an integer (int or long))\n",
      "\t\tphase encode direction of EPI - 1/2/3=x/y/z & -1/-2/-3=-x/-y/-z\n",
      "\t\tflag: -pedir %d\n",
      "\tref_weight: (an existing file name)\n",
      "\t\tFile for reference weighting volume\n",
      "\t\tflag: -refweight %s\n",
      "\trigid2D: (a boolean)\n",
      "\t\tuse 2D rigid body mode - ignores dof\n",
      "\t\tflag: -2D\n",
      "\tsave_log: (a boolean)\n",
      "\t\tsave to log file\n",
      "\tschedule: (an existing file name)\n",
      "\t\treplaces default schedule\n",
      "\t\tflag: -schedule %s\n",
      "\tsearchr_x: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along x-axis, in degrees\n",
      "\t\tflag: -searchrx %s\n",
      "\tsearchr_y: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along y-axis, in degrees\n",
      "\t\tflag: -searchry %s\n",
      "\tsearchr_z: (a list of from 2 to 2 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tsearch angles along z-axis, in degrees\n",
      "\t\tflag: -searchrz %s\n",
      "\tsinc_width: (an integer (int or long))\n",
      "\t\tfull-width in voxels\n",
      "\t\tflag: -sincwidth %d\n",
      "\tsinc_window: (u'rectangular' or u'hanning' or u'blackman')\n",
      "\t\tsinc window\n",
      "\t\tflag: -sincwindow %s\n",
      "\tterminal_output: (u'stream' or u'allatonce' or u'file' or u'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\tuses_qform: (a boolean)\n",
      "\t\tinitialize using sform or qform\n",
      "\t\tflag: -usesqform\n",
      "\tverbose: (an integer (int or long))\n",
      "\t\tverbose mode, 0 is least\n",
      "\t\tflag: -verbose %d\n",
      "\twm_seg: (a file name)\n",
      "\t\twhite matter segmentation volume needed by BBR cost function\n",
      "\t\tflag: -wmseg %s\n",
      "\twmcoords: (a file name)\n",
      "\t\twhite matter boundary coordinates for BBR cost function\n",
      "\t\tflag: -wmcoords %s\n",
      "\twmnorms: (a file name)\n",
      "\t\twhite matter boundary normals for BBR cost function\n",
      "\t\tflag: -wmnorms %s\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\tpath/name of registered file (if generated)\n",
      "\tout_log: (a file name)\n",
      "\t\tpath/name of output log (if generated)\n",
      "\tout_matrix_file: (an existing file name)\n",
      "\t\tpath/name of calculated affine transform (if generated)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FLIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf_coreg = Workflow(name=\"coregistrationPipeline\")\n",
    "wf_coreg.base_dir = \"/home/jovyan/work/preprocess/result\" # Dir where all the outputs will be stored(inside BETFlow folder).\n",
    "\n",
    "\n",
    "wf_coreg.connect([(mcflirt,coreg_step1,[('mean_img','in_file')]), # Sent the mean volume from mcflirt to coreg_step1\n",
    "                  \n",
    "            (BIDSDataGrabber,resample,[('anat_file_path','in_file')]), # Resampled the anat file to 2mm\n",
    "            (resample,coreg_step1,[('out_file','reference')]), # Make the resampled file as reference in coreg_step1\n",
    "            \n",
    "            # Sec 1. The above 3 steps registers the mean image to resampled anat image and calculates the xformation matrix       \n",
    "                  \n",
    "            (mcflirt, coreg_step2, [('out_file', 'in_file')]), # Motion corrected volumes (wrt mean-volume) given as input to coreg_step2  \n",
    "            (resample,coreg_step2,[('out_file','reference')]), # Resampled 2mm anat used as reference to coreg_step2\n",
    "            (coreg_step1, coreg_step2, [('out_matrix_file','in_matrix_file')]),# xformation matrix (mean->anat) is used to transform func volumes to resampled anat\n",
    "            \n",
    "            # Sec 2. The above 3 steps uses the xformation matrix computed in Sec 1. and trasforms the func volumes to resampled anat.        \n",
    "          \n",
    "            (resample, skullStrip, [('out_file','in_file')]), # resampled anat image is skull stripped and mask is generated\n",
    "            (skullStrip, applyMask, [('mask_file','mask_file')]), # the mask is inputted in applyMask\n",
    "            (coreg_step2, applyMask, [('out_file','in_file')]), # The functional image is inputted in applyMask\n",
    "                  \n",
    "            # Sec. 3. The above 3 Steps result is the skull stripping of func data based on mask got from anat\n",
    "                  \n",
    "                  \n",
    "            (skullStrip, coreg_step1_Normalize, [('out_file','in_file')]), # gives the transformation matrix anat->MNI_2mm\n",
    "            \n",
    "            (coreg_step1_Normalize, coreg_step1_Normalize_masking, [('out_file','in_file')]), # masking again the Normalized anat image\n",
    "            (MNI152_2mm_mask, coreg_step1_Normalize_masking, [('mask_file','mask_file')]), # using the mask from MNI152_2mm_mask \n",
    "            \n",
    "             # Sec 4. Above 3 steps masks again the normalized anat and the next statement saves it to dataSink\n",
    "                  \n",
    "            (coreg_step1_Normalize_masking,dataSink,[('out_file','normalized_anat')]), # saving the normalized anatomical file of a subject\n",
    "                 \n",
    "#             # TODO: Now register the functional mean image to the above got normalized anat using coreg_step1\n",
    "#                   # - Need to first create a xformation matrix with:\n",
    "#                   #     - Reference as normalized anat got from - coreg_step1_Normalize_masking\n",
    "#                   #     - in_file = func volume got from - applyMask\n",
    "#                   #     - \n",
    "#             (coreg_step1_Normalize_masking, coreg_step1, [('out_file','reference')]),\n",
    "#             (mcflirt->skullStrip, coreg_step1, [('out_file','in_file')]),    \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "            # Now, apply the matrix got using coreg_step1 to the functional     \n",
    "            \n",
    "                  \n",
    "            (applyMask, coreg_step2_Normalize, [('out_file','in_file')] ), # Applies the transform to the functional file       \n",
    "            (coreg_step1_Normalize, coreg_step2_Normalize, [('out_matrix_file','in_matrix_file')]),\n",
    "                  \n",
    "            (coreg_step2_Normalize, dataSink, [('out_file','normalized_func')]) # saving the normalized functional file of a subject     \n",
    "           \n",
    "            # The above steps transforms the functional to the MNI space using the xformation matrix (resampled_anat -> MNI)      \n",
    "            ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "out_file = <undefined>\n",
       "out_log = <undefined>\n",
       "out_matrix_file = <undefined>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreg_step2_Normalize.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opj(s,'result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band Pass Filtering\n",
    "Let's do a band pass filtering on the data using the code from http://nipype.readthedocs.io/en/latest/users/examples/rsfmri_vol_surface_preprocessing_nipy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bandpass_filter(files, lowpass_freq, highpass_freq, fs):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    import os\n",
    "#     from nipype.utils.config import NUMPY_MMAP\n",
    "    from nipype.utils.filemanip import (filename_to_list, split_filename,\n",
    "                                        list_to_filename)\n",
    "    \"\"\"Bandpass filter the input files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files: list of 4d nifti files\n",
    "    lowpass_freq: cutoff frequency for the low pass filter (in Hz)\n",
    "    highpass_freq: cutoff frequency for the high pass filter (in Hz)\n",
    "    fs: sampling rate (in Hz)\n",
    "    \"\"\"\n",
    "    base_directory = '/home/jovyan/work/preprocess/result'\n",
    "    \n",
    "    out_files = []\n",
    "    for filename in filename_to_list(files):\n",
    "        path, name, ext = split_filename(filename)\n",
    "#         out_file = os.path.join(os.getcwd(), name + '_bp' + ext)\n",
    "        out_file = os.path.join(base_directory, name + '_bp' + ext)\n",
    "        br_img = nb.load(filename)#, mmap=NUMPY_MMAP)\n",
    "        img = br_img.get_data()\n",
    "        timepoints = img.shape[-1]\n",
    "        F = np.zeros((timepoints))\n",
    "        lowidx = int(timepoints / 2) + 1\n",
    "        if lowpass_freq > 0:\n",
    "            lowidx = np.round(float(lowpass_freq) / fs * timepoints)\n",
    "        highidx = 0\n",
    "        if highpass_freq > 0:\n",
    "            highidx = np.round(float(highpass_freq) / fs * timepoints)\n",
    "        F[highidx:lowidx] = 1\n",
    "        F = ((F + F[::-1]) > 0).astype(int)\n",
    "        data = br_img.get_data()\n",
    "        if np.all(F == 1):\n",
    "            filtered_data = data\n",
    "        else:\n",
    "            filtered_data = np.real(np.fft.ifftn(np.fft.fftn(data) * F))\n",
    "        img_out = nb.Nifti1Image(filtered_data, br_img.affine, br_img.header)\n",
    "        img_out.to_filename(out_file)\n",
    "        out_files.append(out_file)\n",
    "    return list_to_filename(out_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Create a Node of the above function and try to execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bandpassFilter = Node(Function(function=bandpass_filter, input_names=['files','lowpass_freq','highpass_freq','fs'],\n",
    "                                output_names=['filtered_func']), name='bandpassFilter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_id = layout.get_subjects()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])] \n",
    "bandpassFilter.inputs.files = func_file_path\n",
    "bandpassFilter.inputs.lowpass_freq = 0.08\n",
    "bandpassFilter.inputs.highpass_freq = 0.001  # Source:https://wiki.biac.duke.edu/biac:analysis:resting_pipeline\n",
    "bandpassFilter.inputs.fs = 1/TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing some Nipype utility functions;\n",
    "from nipype.utils.filemanip import (filename_to_list, split_filename,\n",
    "                                        list_to_filename)\n",
    "\n",
    "func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])] \n",
    "filename_to_list(func_file_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "_img = nib.load('/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz')\n",
    "\n",
    "files = filename_to_list(func_file_path)\n",
    "for filename in filename_to_list(files):\n",
    "    print type(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res = bandpassFilter.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I could not run the Nipype Band pass filter code, So I am resorting to AFNI's band pass function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AFNI\n",
    "\n",
    "func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])] \n",
    "\n",
    "bandpass = afni.Bandpass(in_file=func_file_path[0], highpass=0.008, lowpass=0.08, \n",
    "                         despike=False, no_detrend=True, notrans=True, \n",
    "                         tr=2.0,outputtype='NIFTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171001-18:25:22,951 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:++ 3dBandpass: AFNI version=Debian-16.2.07~dfsg.1-2~nd80+1 (Aug 28 2016) [64-bit]\n",
      "171001-18:25:22,952 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:++ Authored by: RW Cox\n",
      "171001-18:25:22,953 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:\u001b[7m*+ WARNING:\u001b[0m (-: For most purposes, 3dTproject is superior to 3dBandpass :-)\n",
      "171001-18:25:22,954 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:\u001b[7m*+ WARNING:\u001b[0m   If you are performing spatial transformations on an oblique dset, \n",
      "171001-18:25:22,954 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:  such as /home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz,\n",
      "171001-18:25:22,955 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:  or viewing/combining it with volumes of differing obliquity,\n",
      "171001-18:25:22,955 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:  you should consider running: \n",
      "171001-18:25:22,956 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:     3dWarp -deoblique \n",
      "171001-18:25:22,957 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:  on this and  other oblique datasets in the same session.\n",
      "171001-18:25:22,957 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896: See 3dWarp -help for details.\n",
      "171001-18:25:22,958 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:++ Oblique dataset:/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz is 23.000015 degrees from plumb.\n",
      "171001-18:25:22,959 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:++ Data length = 180  FFT length = 180\n",
      "171001-18:25:22,959 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896: + bandpass: ntime=180 nFFT=180 dt=2 dFreq=0.00277778 Nyquist=0.25 passband indexes=3..29\n",
      "171001-18:25:22,960 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:22.950896:++ Loading input dataset time series\n",
      "171001-18:25:23,462 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:23.462214:++ No mask ==> processing all 168960 voxels\n",
      "171001-18:25:24,475 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:24.475566:++ 180 dimensional data reduced to 53 by:\n",
      "171001-18:25:24,476 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:24.475566:    126 (bandpass), 0 (-ort), 0 (-dsort), 1 (detrend)\n",
      "171001-18:25:24,478 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:24.475566:++ Bandpassing data time series\n",
      "171001-18:25:24,980 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:24.980660:++ Creating output dataset in memory, then writing it\n",
      "171001-18:25:26,505 interface INFO:\n",
      "\t stderr 2017-10-01T18:25:26.505248:++ Output dataset ./sub-0050952_task-rest_run-1_bold_bp.nii\n"
     ]
    }
   ],
   "source": [
    "res = bandpass.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/tmp/tmpeyH607/bandpassFilter/sub-0050952_task-rest_run-1_bold_bp.nii'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.outputs.out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/preprocess/result\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/jovyan/work/preprocess/result\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the brain file with name:  /home/jovyan/work/preprocess/result/filtered_func.nii\n"
     ]
    }
   ],
   "source": [
    "load_and_save(res.outputs.out_file,'/home/jovyan/work/preprocess/result/filtered_func.nii')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpeyH607/bandpassFilter\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **3dBandpass**\n",
      "\n",
      "Program to lowpass and/or highpass each voxel time series in a\n",
      "dataset, offering more/different options than Fourier\n",
      "\n",
      "For complete details, see the `3dBandpass Documentation.\n",
      "<https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dBandpass.html>`_\n",
      "\n",
      "Examples\n",
      "========\n",
      "\n",
      ">>> from nipype.interfaces import afni\n",
      ">>> from nipype.testing import  example_data\n",
      ">>> bandpass = afni.Bandpass()\n",
      ">>> bandpass.inputs.in_file = 'functional.nii'\n",
      ">>> bandpass.inputs.highpass = 0.005\n",
      ">>> bandpass.inputs.lowpass = 0.1\n",
      ">>> bandpass.cmdline  # doctest: +ALLOW_UNICODE\n",
      "'3dBandpass -prefix functional_bp 0.005000 0.100000 functional.nii'\n",
      ">>> res = bandpass.run()  # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\thighpass: (a float)\n",
      "\t\thighpass\n",
      "\t\tflag: %f, position: -3\n",
      "\tin_file: (an existing file name)\n",
      "\t\tinput file to 3dBandpass\n",
      "\t\tflag: %s, position: -1\n",
      "\tlowpass: (a float)\n",
      "\t\tlowpass\n",
      "\t\tflag: %f, position: -2\n",
      "\n",
      "\t[Optional]\n",
      "\targs: (a unicode string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tautomask: (a boolean)\n",
      "\t\tCreate a mask from the input dataset.\n",
      "\t\tflag: -automask\n",
      "\tblur: (a float)\n",
      "\t\tBlur (inside the mask only) with a filter width (FWHM) of 'fff'\n",
      "\t\tmillimeters.\n",
      "\t\tflag: -blur %f\n",
      "\tdespike: (a boolean)\n",
      "\t\tDespike each time series before other processing. Hopefully, you\n",
      "\t\tdon't actually need to do this, which is why it is optional.\n",
      "\t\tflag: -despike\n",
      "\tenviron: (a dictionary with keys which are a newbytes or None or a\n",
      "\t\t newstr or None and with values which are a newbytes or None or a\n",
      "\t\t newstr or None, nipype default value: {})\n",
      "\t\tEnvironment variables\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tlocalPV: (a float)\n",
      "\t\tReplace each vector by the local Principal Vector (AKA first\n",
      "\t\tsingular vector) from a neighborhood of radius 'rrr' millimeters.\n",
      "\t\tNote that the PV time series is L2 normalized. This option is mostly\n",
      "\t\tfor Bob Cox to have fun with.\n",
      "\t\tflag: -localPV %f\n",
      "\tmask: (an existing file name)\n",
      "\t\tmask file\n",
      "\t\tflag: -mask %s, position: 2\n",
      "\tnfft: (an integer (int or long))\n",
      "\t\tSet the FFT length [must be a legal value].\n",
      "\t\tflag: -nfft %d\n",
      "\tno_detrend: (a boolean)\n",
      "\t\tSkip the quadratic detrending of the input that occurs before the\n",
      "\t\tFFT-based bandpassing. You would only want to do this if the dataset\n",
      "\t\thad been detrended already in some other program.\n",
      "\t\tflag: -nodetrend\n",
      "\tnormalize: (a boolean)\n",
      "\t\tMake all output time series have L2 norm = 1 (i.e., sum of squares =\n",
      "\t\t1).\n",
      "\t\tflag: -norm\n",
      "\tnotrans: (a boolean)\n",
      "\t\tDon't check for initial positive transients in the data. The test is\n",
      "\t\ta little slow, so skipping it is OK, if you KNOW the data time\n",
      "\t\tseries are transient-free.\n",
      "\t\tflag: -notrans\n",
      "\torthogonalize_dset: (an existing file name)\n",
      "\t\tOrthogonalize each voxel to the corresponding voxel time series in\n",
      "\t\tdataset 'fset', which must have the same spatial and temporal grid\n",
      "\t\tstructure as the main input dataset. At present, only one '-dsort'\n",
      "\t\toption is allowed.\n",
      "\t\tflag: -dsort %s\n",
      "\torthogonalize_file: (a list of items which are an existing file name)\n",
      "\t\tAlso orthogonalize input to columns in f.1D. Multiple '-ort' options\n",
      "\t\tare allowed.\n",
      "\t\tflag: -ort %s\n",
      "\tout_file: (a file name)\n",
      "\t\toutput file from 3dBandpass\n",
      "\t\tflag: -prefix %s, position: 1\n",
      "\toutputtype: (u'NIFTI_GZ' or u'AFNI' or u'NIFTI')\n",
      "\t\tAFNI output filetype\n",
      "\tterminal_output: (u'stream' or u'allatonce' or u'file' or u'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\ttr: (a float)\n",
      "\t\tSet time step (TR) in sec [default=from dataset header].\n",
      "\t\tflag: -dt %f\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\toutput file\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "afni.Bandpass.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFNI's filter is working good:\n",
    "Next:\n",
    "Add the mask as parameter to the afni Node\n",
    "Add the Node to the workflow\n",
    "Improve the data sink\n",
    "Crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171001-18:11:12,170 workflow INFO:\n",
      "\t Workflow preprocessPipeline settings: ['check', 'execution', 'logging']\n",
      "171001-18:11:12,199 workflow INFO:\n",
      "\t Running in parallel.\n",
      "171001-18:11:12,214 workflow INFO:\n",
      "\t Executing: BIDSDataGrabber.aI.a0 ID: 0\n",
      "171001-18:11:12,216 workflow INFO:\n",
      "\t [Job finished] jobname: BIDSDataGrabber.aI.a0 jobid: 0\n",
      "171001-18:11:12,218 workflow INFO:\n",
      "\t Executing: BIDSDataGrabber.aI.a1 ID: 5\n",
      "171001-18:11:12,220 workflow INFO:\n",
      "\t [Job finished] jobname: BIDSDataGrabber.aI.a1 jobid: 5\n",
      "171001-18:11:12,223 workflow INFO:\n",
      "\t Executing: resample.a0 ID: 1\n",
      "171001-18:11:12,249 workflow INFO:\n",
      "\t [Job finished] jobname: resample.a0 jobid: 1\n",
      "171001-18:11:12,251 workflow INFO:\n",
      "\t Executing: resample.a1 ID: 6\n",
      "171001-18:11:12,255 workflow INFO:\n",
      "\t [Job finished] jobname: resample.a1 jobid: 6\n",
      "171001-18:11:12,257 workflow INFO:\n",
      "\t Executing: extract.a0 ID: 7\n",
      "171001-18:11:12,261 workflow INFO:\n",
      "\t [Job finished] jobname: extract.a0 jobid: 7\n",
      "171001-18:11:12,263 workflow INFO:\n",
      "\t Executing: extract.a1 ID: 16\n",
      "171001-18:11:12,267 workflow INFO:\n",
      "\t [Job finished] jobname: extract.a1 jobid: 16\n",
      "171001-18:11:12,270 workflow INFO:\n",
      "\t Executing: skullStrip.a0 ID: 2\n",
      "171001-18:11:12,275 workflow INFO:\n",
      "\t [Job finished] jobname: skullStrip.a0 jobid: 2\n",
      "171001-18:11:12,277 workflow INFO:\n",
      "\t Executing: slicetimer.a0 ID: 8\n",
      "171001-18:11:12,283 workflow INFO:\n",
      "\t [Job finished] jobname: slicetimer.a0 jobid: 8\n",
      "171001-18:11:12,285 workflow INFO:\n",
      "\t Executing: skullStrip.a1 ID: 15\n",
      "171001-18:11:12,290 workflow INFO:\n",
      "\t [Job finished] jobname: skullStrip.a1 jobid: 15\n",
      "171001-18:11:12,291 workflow INFO:\n",
      "\t Executing: slicetimer.a1 ID: 17\n",
      "171001-18:11:12,297 workflow INFO:\n",
      "\t [Job finished] jobname: slicetimer.a1 jobid: 17\n",
      "171001-18:11:12,301 workflow INFO:\n",
      "\t Executing: coreg_step1_Normalize.a0 ID: 3\n",
      "171001-18:11:12,306 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1_Normalize.a0 jobid: 3\n",
      "171001-18:11:12,308 workflow INFO:\n",
      "\t Executing: mcflirt.a0 ID: 9\n",
      "171001-18:11:12,313 workflow INFO:\n",
      "\t [Job finished] jobname: mcflirt.a0 jobid: 9\n",
      "171001-18:11:12,315 workflow INFO:\n",
      "\t Executing: mcflirt.a1 ID: 18\n",
      "171001-18:11:12,322 workflow INFO:\n",
      "\t [Job finished] jobname: mcflirt.a1 jobid: 18\n",
      "171001-18:11:12,324 workflow INFO:\n",
      "\t Executing: coreg_step1_Normalize.a1 ID: 22\n",
      "171001-18:11:12,332 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1_Normalize.a1 jobid: 22\n",
      "171001-18:11:12,336 workflow INFO:\n",
      "\t Executing: coreg_step1_Normalize_masking.a0 ID: 4\n",
      "171001-18:11:12,357 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1_Normalize_masking.a0 jobid: 4\n",
      "171001-18:11:12,359 workflow INFO:\n",
      "\t Executing: coreg_step1.a0 ID: 10\n",
      "171001-18:11:12,370 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1.a0 jobid: 10\n",
      "171001-18:11:12,371 workflow INFO:\n",
      "\t Executing: coreg_step1.a1 ID: 19\n",
      "171001-18:11:12,381 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1.a1 jobid: 19\n",
      "171001-18:11:12,382 workflow INFO:\n",
      "\t Executing: coreg_step1_Normalize_masking.a1 ID: 23\n",
      "171001-18:11:12,389 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step1_Normalize_masking.a1 jobid: 23\n",
      "171001-18:11:12,392 workflow INFO:\n",
      "\t Executing: coreg_step2.a0 ID: 11\n",
      "171001-18:11:12,406 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step2.a0 jobid: 11\n",
      "171001-18:11:12,408 workflow INFO:\n",
      "\t Executing: coreg_step2.a1 ID: 20\n",
      "171001-18:11:12,422 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step2.a1 jobid: 20\n",
      "171001-18:11:12,425 workflow INFO:\n",
      "\t Executing: applyMask.a0 ID: 12\n",
      "171001-18:11:12,436 workflow INFO:\n",
      "\t [Job finished] jobname: applyMask.a0 jobid: 12\n",
      "171001-18:11:12,437 workflow INFO:\n",
      "\t Executing: applyMask.a1 ID: 21\n",
      "171001-18:11:12,447 workflow INFO:\n",
      "\t [Job finished] jobname: applyMask.a1 jobid: 21\n",
      "171001-18:11:12,451 workflow INFO:\n",
      "\t Executing: coreg_step2_Normalize.a0 ID: 13\n",
      "171001-18:11:12,461 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step2_Normalize.a0 jobid: 13\n",
      "171001-18:11:12,462 workflow INFO:\n",
      "\t Executing: coreg_step2_Normalize.a1 ID: 24\n",
      "171001-18:11:12,472 workflow INFO:\n",
      "\t [Job finished] jobname: coreg_step2_Normalize.a1 jobid: 24\n",
      "171001-18:11:12,474 workflow INFO:\n",
      "\t Executing: datasink.a0 ID: 14\n",
      "171001-18:11:12,485 workflow INFO:\n",
      "\t Executing: datasink.a1 ID: 25\n",
      "171001-18:11:12,488 workflow INFO:\n",
      "\t Executing node datasink.a0 in dir: /home/jovyan/work/preprocess/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050952/datasink\n",
      "171001-18:11:12,501 workflow INFO:\n",
      "\t Executing node datasink.a1 in dir: /home/jovyan/work/preprocess/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050953/datasink\n",
      "171001-18:11:12,531 workflow INFO:\n",
      "\t [Job finished] jobname: datasink.a0 jobid: 14\n",
      "171001-18:11:12,537 workflow INFO:\n",
      "\t [Job finished] jobname: datasink.a1 jobid: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fd8d8ef2950>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the workflow\n",
    "# Refer to Supplementary material's Section Two for more on workspaces\n",
    "\n",
    "wf = Workflow(name=\"preprocessPipeline\")\n",
    "base_dir = opj(s,'result')\n",
    "wf.base_dir = base_dir # Dir where all the outputs will be stored(inside BETFlow folder).\n",
    "# (infosource, BIDSDataGrabber, [('data_dir','data_dir'), ('subject_id', 'subject_id'),]),\n",
    "\n",
    "wf.connect([      (BIDSDataGrabber, extract, [('func_file_path','in_file')]),\n",
    "                  (extract,slicetimer,[('roi_file','in_file')]),\n",
    "                  (slicetimer,wf_coreg,[('slice_time_corrected_file','mcflirt.in_file')]),\n",
    "           ])\n",
    "# Run it in parallel (one core for each smoothing kernel)\n",
    "wf.run('MultiProc', plugin_args={'n_procs': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TODO: Apply mni2mm mask on 2mm resampled anat brain and then  co-register the func on that \n",
    "    instead of unmasked 2mm anat brain\n",
    "    coz 2mm brain is expanded and so the functional is expanded even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "from IPython.display import Image\n",
    "wf.write_graph(graph2use='exec', format='png', simple_form=True)\n",
    "file_name = opj(base_directory,'preprocessPipeline/graph_detailed.dot.png')\n",
    "Image(filename=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Summary [Incomplete]\n",
    "```\n",
    "wf.connect([(infosource, BIDSDataGrabber, [('data_dir','data_dir'), ('subject_id', 'subject_id'),]),\n",
    "                  (BIDSDataGrabber, extract, [('func_file_path','in_file')]),\n",
    "                  (extract,slicetimer,[('roi_file','in_file')]),\n",
    "                  (slicetimer,mcflirt,[('slice_time_corrected_file','in_file')]),\n",
    "                  (mcflirt, skullStrip, [('mean_img', 'in_file')]),\n",
    "                  (mcflirt,applyMask,[('out_file','brain_file')]),\n",
    "                  (skullStrip, applyMask, [('mask_file', 'mask_file')]), \n",
    "                  ])\n",
    "```\n",
    "\n",
    "In the above created workflow the `infosource` node iterates over the `subject_id`, it creates a Node and for each Subject ID it sends `data_dir` (path where the data resides) and the subject specific `subject_id` to `BIDSDataGrabber` Node.\n",
    "\n",
    "`BIDSDataGrabber` Node accepts the above 2 parameters, calls the function `get_nifti_filenames(subject_id,data_dir)`which returns the path of the anatomical and BOLD files of the subject with given subject_id and hence the Node produces output that I call `func_file_path` and `anat_file_path`. I have used only `func_file_path`right now.\n",
    "\n",
    "The file path denoted by '``func_file_path``' is then fed as input to `extract` that removes 4 initial brain volumes of the functional scan.\n",
    "\n",
    "Its output is called - `slice_time_corrected_file` which is fed to `mcflirt` node to correct the movion between volumes of an individual subject. This is called **Motion Correction**.\n",
    "\n",
    "In next step the mean_image from `mcflirt` is sent to `skullStrip` to get the mask. The role of `skullStrip` is just to obtain mask from the mean EPI image.\n",
    "\n",
    "The mask got above is then applied to the functional volume to get rif of skull.\n",
    "\n",
    "\n",
    "\n",
    "The final results are stored in the directory : `/home/jovyan/work/preprocess/result/BETFlow`. Every node has its own folder where its results are stored.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To load and save a brain image to a convenient location so that I can view it in fslview\n",
    "import nibabel as nib\n",
    "\n",
    "def load_and_save(filepath, name):\n",
    "    brain_data = nib.load(filepath)\n",
    "#     brain_tensor = brain_data.get_data()\n",
    "\n",
    "    print \"Saving the brain file with name: \", name\n",
    "    # brain_MC_with_header = nib.Nifti1Image(fullbrain_atlas, affine=bn.affine,header = bn.header)\n",
    "    nib.save(brain_data, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load_and_save(str(res.outputs.slice_time_corrected_file), 'slicetimecorrectedfile_50954)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MCFLIRT.help()\n",
    "# To Stop execution Raise error:\n",
    "raise Exception('Execution stops here!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One\n",
    "\n",
    ">### Arguments for  extracting relevent files\n",
    "Anatomical files:  \n",
    "filename='..._T1w.nii.gz', type='T1w', modality='anat', subject='0050952'\n",
    "\n",
    ">Functional files:  \n",
    "filename='..._bold.nii.gz',type='bold', task='rest', run='1', modality='func', subject='0050952'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By typing \n",
    "layout.get()\n",
    "# I get all the filenames with their parameters that I can use to extract the relevent files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two\n",
    ">## Constructing a workflow  \n",
    "To make a workflow you need the input and output names of the Nodes.  \n",
    "- > **Example workflow**:  \n",
    "```wf.connect([(<Source_Node>, <Destination_Node>, [('<output_from_source_node>','<input_to_destination_node>')])```\n",
    "- To get the name of input for a Node type ```<Node_Name>.inputs```  \n",
    "- To get the name of output of a Node write ```<Node_Name>.outputs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for example, to get the the input info of ExtractROI Node type:\n",
    "extract.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to get the the input info of ExtractROI Node type:\n",
    "extract.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skullStrip.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #Lets move ahead with creating more Nodes for preprocessing.  \n",
    "\n",
    "# #Extract ROI for skipping first 4 scans of the functional data \n",
    "\n",
    "# # ExtractROI - skip dummy scans\n",
    "# extract = Node(ExtractROI(t_min=4, t_size=-1),\n",
    "#                output_type='NIFTI',\n",
    "#                name=\"extract\")\n",
    "\n",
    "# #Do motion correction. So as to ensure that for a subject each brain volume is 'insync' with the other volume.\n",
    "\n",
    "# # MCFLIRT - motion correction\n",
    "# mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "#                        save_plots=True,\n",
    "#                        output_type='NIFTI'),\n",
    "#                name=\"mcflirt\")\n",
    "\n",
    "# # To test mcflirt\n",
    "# mcflirt.inputs.in_file = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz'\n",
    "# res_mcflirt = mcflirt.run()\n",
    "# res_mcflirt.outputs\n",
    "\n",
    "# ### To Visulize the output of mcflirt\n",
    "# 1. Displayed in notebook only one volume using nilearn\n",
    "# 2. Plotted histogram of original and corrected files\n",
    "# 3. Saved copies of original and corrected files using nibabel to see in fslview\n",
    "\n",
    "# from nilearn import image\n",
    "\n",
    "# brain = image.load_img('/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz')\n",
    "# brain_MC = image.load_img('/tmp/tmpZG2rZL/mcflirt/sub-0050954_task-rest_run-1_bold_mcf.nii')\n",
    "\n",
    "\n",
    "# tenth_brain = image.index_img(brain, 30)\n",
    "# tenth_brain_MC = image.index_img(brain_MC, 30)\n",
    "\n",
    "\n",
    "# %pylab inline\n",
    "# from nilearn.plotting import plot_anat\n",
    "# plot_anat(tenth_brain, title='Original',\n",
    "#           display_mode='ortho', dim=-1, draw_cross=False, annotate=False)\n",
    "\n",
    "\n",
    "# from nilearn.plotting import plot_anat\n",
    "# plot_anat(tenth_brain_MC, title='Motion Corrected',\n",
    "#           display_mode='ortho', dim=-1, draw_cross=False, annotate=False)\n",
    "\n",
    "# #The output as well as input looked washed out. So checked the intensity values of the brain\n",
    "\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "\n",
    "# brain_original = nib.load('/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz')\n",
    "# brain_MC = nib.load('/tmp/tmpZG2rZL/mcflirt/sub-0050954_task-rest_run-1_bold_mcf.nii')\n",
    "\n",
    "# # checked max and min values of original brain\n",
    "# np.max(brain_original.get_data()),np.min(brain_original.get_data())\n",
    "\n",
    "# # checked max and min values of corrected brain\n",
    "# np.max(brain_MC.get_data()),np.min(brain_MC.get_data())\n",
    "\n",
    "# # checked how many unique floor(values) does the brain has\n",
    "# (np.unique(np.floor(brain_MC.get_data())))\n",
    "\n",
    "# # Plotted the histogram\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# brain_original_flattened = (brain_original.get_data()).flatten()\n",
    "# brain_MC_flattened = (brain_MC.get_data()).flatten()\n",
    "\n",
    "# plt.hist(brain_flattened)\n",
    "\n",
    "\n",
    "\n",
    "# plt.hist(brain_MC_flattened)\n",
    "\n",
    "# # Save the motion corrected brain to analyze if it is correct\n",
    "\n",
    "# print \"Saving the Motion corrected brain \"\n",
    "# # brain_MC_with_header = nib.Nifti1Image(fullbrain_atlas, affine=bn.affine,header = bn.header)\n",
    "# nib.save(brain_MC, 'motion_corrected_50594')\n",
    "\n",
    "\n",
    "# # After seeing it in fslview, I conclude that the overall conrast has been reduced and brain image has become dull as seen in the histogram. I don't know if this is correct or not but this is th output that I got by applying MCFLIRT on the given fmri data for subject 50594\n",
    "\n",
    "# # Do slice time correction  \n",
    "# # > **Arguments**:  \n",
    "# # index_dir=False -> Slices were taken bottom to top i.e. in ascending order  \n",
    "# # interleaved=True means odd slices were acquired first and then even slices [or vice versa(Not sure)] \n",
    "\n",
    "# # slicetimer = Node(SliceTimer(index_dir=False,\n",
    "# #                              interleaved=True,\n",
    "# #                              output_type='NIFTI',\n",
    "# #                              time_repetition=TR),\n",
    "# #                   name=\"slicetimer\")\n",
    "\n",
    "# # slicetimer.inputs.in_file = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz'\n",
    "# # res = slicetimer.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mcflirt.outputs\n",
    "\n",
    "# skullStrip.inputs\n",
    "\n",
    "# skullStrip.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Testing applying mask on functional data \n",
    "\n",
    "# # def applyMask_func(brain_file, mask_file):\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "# import os\n",
    "\n",
    "# brain_file = '/home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050954/func/sub-0050954_task-rest_run-1_bold.nii.gz'\n",
    "# mean_file = '/tmp/tmpVHzuw1/mcflirt/sub-0050954_task-rest_run-1_bold_mcf.nii_mean_reg.nii'\n",
    "\n",
    "# skullStrip.inputs.in_file = mean_file\n",
    "# res = skullStrip.run()\n",
    "\n",
    "# mask_file = str(res.outputs.mask_file)\n",
    "\n",
    "# brain_data = nib.load(brain_file)\n",
    "# mask_data = nib.load(mask_file)\n",
    "\n",
    "# brain = brain_data.get_data()\n",
    "# mask = mask_data.get_data()\n",
    "\n",
    "# for t in range(brain.shape[-1]):\n",
    "#     brain[:,:,:,t] = np.multiply(brain[:,:,:,t],mask)\n",
    "\n",
    "# # Saving the brain file\n",
    "\n",
    "# func_brain_path = mask_file + '_func_brain.nii.gz'\n",
    "\n",
    "# brain_with_header = nib.Nifti1Image(brain, affine=brain_data.affine,header = brain_data.header)\n",
    "# nib.save(brain_with_header,func_brain_path)\n",
    "\n",
    "# # save at the local PWD to see using fsl\n",
    "# load_and_save(func_brain_path,'skul_stripped_50954')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# str(res.outputs.slice_time_corrected_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.afni import Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-Registration and Normalization [Link](https://en.wikibooks.org/wiki/Neuroimaging_Data_Processing/Coregistration_and_Normalization#Concept_of_Coregistration)\n",
    "1. Register the mean EPI image to Highres Anatomical image\n",
    "2. Register the Highres Anatomical image to Standard space\n",
    "3. Use the Transformation Matrix got in (2.) to register the EPI images to standard space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the mean EPI image to Highres Anatomical image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FLIRT - coregister functional images to anatomical images\n",
    "coreg_step1 = Node(FLIRT(output_type='NIFTI'), name=\"coreg_step1\")\n",
    "\n",
    "coreg_step2 = Node(FLIRT(output_type='NIFTI',\n",
    "                         apply_xfm=True), name=\"coreg_step2\")\n",
    "\n",
    "coreg_step1_Normalize = Node(FLIRT(reference='/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz',\n",
    "                         output_type='NIFTI'), name=\"coreg_step1_Normalize\")\n",
    "\n",
    "coreg_step2_Normalize = Node(FLIRT(reference='/usr/share/fsl/5.0/data/standard/MNI152_T1_2mm_brain.nii.gz',\n",
    "                         output_type='NIFTI', apply_xfm=True), name=\"coreg_step2_Normalize\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# wf.connect([(mcflirt,skullStrip,[('mean_img','in_file')]),\n",
    "#             (BIDSDataGrabber,skullStrip,[('anat_file_path','in_file')]),\n",
    "#             (skullStrip,coreg_step1,[('out_file','reference')]),\n",
    "#             (skullStrip,coreg_step1,[('mask_file','reference')]),\n",
    "#             (skullStrip,coreg_step2,[('out_file','in_file')])\n",
    "#            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add this to the main workflow. (First 2)It Registers the functional image to anatomical image\n",
    "\n",
    "template = Info.standard_image('MNI152_T1_2mm_brain.nii.gz') # path of the MNI tempelate in unicode\n",
    "```\n",
    "wf.connect([(mcflirt,coreg_step1,[('mean_img','in_file')]),\n",
    "            (BIDSDataGrabber,coreg_step1,[('anat_file_path','reference')]), # Mean functional and anatomical file given as input to coreg_step to register mean functional to anatomical scan\n",
    "            \n",
    "            (mcflirt, coreg_step2, [('out_file', 'in_file')]), \n",
    "            (BIDSDataGrabber,coreg_step2,[('anat_file_path','reference')]),\n",
    "            (coreg_step1, coreg_step2, [('out_matrix_file','in_matrix_file')]),  # Sending the transformation matrix, refrence file, and the input file. Input file is transformed using the transformation matrix     \n",
    "            \n",
    "            (BIDSDataGrabber, skullStrip, [('anat_file_path','in_file')]), # Skull stripping the anat file,\n",
    "            (skullStrip, applyMask, [('mask_file','mask_file')]),\n",
    "            (coreg_step2,applyMask, [('out_file','brain_file')], # generating mask and applying it to functional data of subject\n",
    "            \n",
    "            #-------- Now register the anatomical brain (skullStrip's out fie) to the MNI brain\n",
    "             \n",
    "            (skullStrip, coreg_step1, [('out_file','in_file')])\n",
    "            \n",
    "             ])\n",
    "            \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "-- need to code for rest 2 to get the xform matrix from anat to mni\n",
    "-- apply xform to all the functional images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf_coreg = Workflow(name=\"coregistrationPipeline\")\n",
    "wf_coreg.base_dir = \"/home/jovyan/work/preprocess/result_coreg\" # Dir where all the outputs will be stored(inside BETFlow folder).\n",
    "\n",
    "\n",
    "wf_coreg.connect([(mcflirt,coreg_step1,[('mean_img','in_file')]),\n",
    "            (BIDSDataGrabber,coreg_step1,[('anat_file_path','reference')]),\n",
    "            \n",
    "            (mcflirt, coreg_step2, [('out_file', 'in_file')]), \n",
    "            (BIDSDataGrabber,coreg_step2,[('anat_file_path','reference')]),\n",
    "            (coreg_step1, coreg_step2, [('out_matrix_file','in_matrix_file')]),\n",
    "            \n",
    "            (BIDSDataGrabber, skullStrip, [('anat_file_path','in_file')]),\n",
    "            (skullStrip, applyMask, [('mask_file','mask_file')]),\n",
    "            (coreg_step2, applyMask, [('out_file','brain_file')]),\n",
    "             \n",
    "            (skullStrip, coreg_step1_Normalize, [('out_file','in_file')]), # gives the transformation matrix\n",
    "            \n",
    "            (applyMask, coreg_step2_Normalize, [('out_file','in_file')] ) # Applies the transform to the functional file       \n",
    "                  \n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "from IPython.display import Image\n",
    "wf_coreg.write_graph(graph2use='exec', format='png', simple_form=True)\n",
    "\n",
    "Image(filename='/home/jovyan/work/preprocess/result/coregistrationPipeline/graph_detailed.dot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization using ANTS\n",
    "from nipype.interfaces.ants import ApplyTransforms\n",
    "\n",
    "from nipype.interfaces.fsl import Info\n",
    "# Template to normalize to\n",
    "template = Info.standard_image('MNI152_T1_2mm_brain.nii.gz') # path of the MNI tempelate in unicode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "fslstats /usr/share/fsl/5.0/data/standard/MNI152_T1_2mm.nii.gz -v\n",
    "\n",
    "fslstats ../data/ABIDE-BIDS/NYU/sub-0050954/anat/sub-0050954_T1w.nii.gz -v\n",
    "\n",
    "#fslinfo /usr/share/fsl/5.0/data/standard/MNI152_T1_2mm.nii.gz\n",
    "fslview /usr/share/fsl/5.0/data/standard/MNI152_T1_2mm.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I came to know from someone that for FLIRT to work fine, the volume of refrence and input file must be same. That is,  \n",
    "\n",
    ">`n1 x voxel_volume = n1 x voxel_volume`  \n",
    "\n",
    "n1 : Number of volxels in brain 1\n",
    "n2 : Number of volxels in brain 2\n",
    "\n",
    "Voxel volume = mm x mm x mm\n",
    "\n",
    "fslstats told me that brain volumes are not same. Lets see how the registration goes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Transformation - applies the normalization matrix to contrast images\n",
    "apply2con = Node(ApplyTransforms(args='--float',\n",
    "                                    input_image_type=3,\n",
    "                                    interpolation='Linear',\n",
    "                                    invert_transform_flags=[False],\n",
    "                                    num_threads=8,\n",
    "                                    reference_image=template,\n",
    "                                    terminal_output='file'),\n",
    "                                name='apply2con')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coreg_step2.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skullStrip.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applyMask.inputs.in_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applyMask.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Old workflow:\n",
    "# Create the workflow\n",
    "# Refer to Supplementary material's Section Two for more on workspaces\n",
    "\n",
    "wf = Workflow(name=\"preprocessPipeline\")\n",
    "wf.base_dir = \"/home/jovyan/work/preprocess/result\" # Dir where all the outputs will be stored(inside BETFlow folder).\n",
    "\n",
    "wf.connect([(infosource, BIDSDataGrabber, [('data_dir','data_dir'), ('subject_id', 'subject_id'),]),\n",
    "                  (BIDSDataGrabber, extract, [('func_file_path','in_file')]),\n",
    "                  (extract,slicetimer,[('roi_file','in_file')]),\n",
    "                  (slicetimer,mcflirt,[('slice_time_corrected_file','in_file')]),\n",
    "                  (mcflirt, skullStrip, [('mean_img', 'in_file')]),\n",
    "                  (mcflirt,applyMask,[('out_file','in_file')]),\n",
    "                  (skullStrip, applyMask, [('mask_file', 'mask_file')]), \n",
    "                  ])\n",
    "# Run it in parallel (one core for each smoothing kernel)\n",
    "wf.run('MultiProc', plugin_args={'n_procs': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spending too much time in:\n",
    "#flirt -in /home/jovyan/work/preprocess/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050952/mcflirt/sub-0050952_task-rest_run-1_bold_roi_st_mcf.nii -ref /home/jovyan/work/preprocess/data/ABIDE-BIDS/NYU/sub-0050952/anat/sub-0050952_T1w.nii.gz -out sub-0050952_task-rest_run-1_bold_roi_st_mcf_flirt.nii -omat sub-0050952_task-rest_run-1_bold_roi_st_mcf_flirt.mat -applyxfm -init /home/jovyan/work/preprocess/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050952/coreg_step1/sub-0050952_task-rest_run-1_bold_roi_st_mcf.nii_mean_reg_flirt.mat\n",
    "\n",
    "flirt -in bold_roi_st_mcf.nii\n",
    "      -ref T1w.nii.gz \n",
    "      -out bold_roi_st_mcf_flirt.nii\n",
    "      -omat bold_roi_st_mcf_flirt.mat \n",
    "      -applyxfm \n",
    "      -init bold_roi_st_mcf.nii_mean_reg_flirt.mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!flirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TODO: \n",
    "    - Clean the code\n",
    "    - Add extra supplementary material if needed\n",
    "    - Try to Normalize the functional data to the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

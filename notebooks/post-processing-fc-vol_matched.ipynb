{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing:\n",
    "* Global Signal Regression using orthogonalization\n",
    "* Band Pass filtering 0.1 - 0.01 Hz\n",
    "* Motion regression using GLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bids.grabbids import BIDSLayout\n",
    "from nipype.interfaces.fsl import (BET, ExtractROI, FAST, FLIRT, ImageMaths,\n",
    "                                   MCFLIRT, SliceTimer, Threshold,Info, ConvertXFM,MotionOutliers)\n",
    "from nipype.interfaces.afni import Resample\n",
    "from nipype.interfaces.io import DataSink\n",
    "from nipype.pipeline import Node, MapNode, Workflow, JoinNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from nipype.interfaces import afni\n",
    "import nibabel as nib\n",
    "import json    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "path_cwd = os.getcwd()\n",
    "path_split_list = path_cwd.split('/')\n",
    "s = path_split_list[0:-2] # for getting to the parent dir of pwd\n",
    "s = opj('/',*s) # *s converts list to path, # very important to add '/' in the begining so it is read as directory later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# json_path = opj(data_directory,'task-rest_bold.json')\n",
    "\n",
    "json_path = '../scripts/json/paths.json'\n",
    "with open(json_path, 'rt') as fp:\n",
    "    task_info = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_directory = opj(s,'result') \n",
    "# parent_wf_directory = 'preprocessPipeline_ABIDE2_GU1_withfloat'\n",
    "# child_wf_directory = 'coregistrationPipeline'\n",
    "\n",
    "# data_directory = opj(s,\"data/ABIDE2-BIDS/GU1\")\n",
    "\n",
    "# datasink_name = 'datasink_preprocessed_ABIDE2_GU1_withfloat'\n",
    "\n",
    "base_directory = opj(s,task_info[\"base_directory_for_results\"]) \n",
    "motion_correction_bet_directory = task_info[\"motion_correction_bet_directory\"]\n",
    "parent_wf_directory = task_info[\"parent_wf_directory\"]\n",
    "# functional_connectivity_directory = task_info[\"functional_connectivity_directory\"]\n",
    "functional_connectivity_directory = 'temp_fc'\n",
    "coreg_reg_directory = task_info[\"coreg_reg_directory\"]\n",
    "atlas_resize_reg_directory = task_info[\"atlas_resize_reg_directory\"]\n",
    "data_directory = opj(s,task_info[\"data_directory\"])\n",
    "datasink_name = task_info[\"datasink_name\"]\n",
    "fc_datasink_name = task_info[\"fc_datasink_name\"]\n",
    "fc_datasink_name = 'temp_dataSink'\n",
    "atlasPath = opj(s,task_info[\"atlas_path\"])\n",
    "\n",
    "\n",
    "# mask_file = '/media/varun/LENOVO4/Projects/result/preprocessPipeline/coregistrationPipeline/_subject_id_0050952/skullStrip/sub-0050952_T1w_resample_brain_mask.nii.gz'\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opj(base_directory,parent_wf_directory,motion_correction_bet_directory,coreg_reg_directory,'resample_mni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_path = opj(base_directory,datasink_name,'preprocessed_brain_paths/brain_file_list.npy')\n",
    "mask_path = opj(base_directory,datasink_name,'preprocessed_mask_paths/mask_file_list.npy')\n",
    "atlas_path = opj(base_directory,datasink_name,'atlas_paths/atlas_file_list.npy')\n",
    "tr_path = opj(base_directory,datasink_name,'tr_paths/tr_list.npy')\n",
    "motion_params_path = opj(base_directory,datasink_name,'motion_params_paths/motion_params_file_list.npy')\n",
    "\n",
    "func2std_mat_path = opj(base_directory, datasink_name,'joint_xformation_matrix_paths/joint_xformation_matrix_file_list.npy')\n",
    "\n",
    "MNI3mm_path = opj(base_directory,parent_wf_directory,motion_correction_bet_directory,coreg_reg_directory,'resample_mni/MNI152_T1_2mm_brain_resample.nii') \n",
    "\n",
    "# brain_list = np.load('../results_again_again/ABIDE1_Preprocess_Datasink/preprocessed_brain_paths/brain_file_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brain_path,mask_path,atlas_path,tr_path,motion_params_path,func2std_mat_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brain_path = np.load(brain_path)\n",
    "mask_path = np.load(mask_path)\n",
    "atlas_path = np.load(atlas_path)\n",
    "tr_path = np.load(tr_path)\n",
    "motion_params_path = np.load(motion_params_path)\n",
    "func2std_mat_path = np.load(func2std_mat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a,b,c,d,e in zip(brain_path,mask_path,atlas_path,tr_path,motion_params_path):\n",
    "#     print (a,b,c,d,e,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout = BIDSLayout(data_directory)\n",
    "\n",
    "number_of_subjects = 2 # Number of subjects you wish to preprocess\n",
    "# number_of_subjects = len(layout.get_subjects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Data directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(layout.get_subjects()) # working!Gives us list of all the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layout.get_subjects();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the metadata associated with a subject. [Takes as argumment the filename of subject ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_list = (layout.get_subjects())#[0:number_of_subjects]\n",
    "subject_list = list(map(int, subject_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which subjects have volumes > 'vol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "demographics_file_path = '/home1/varunk/Autism-Connectome-Analysis-brain_connectivity/notebooks/demographics.csv'\n",
    "phenotype_file_path = '/home1/varunk/data/ABIDE1/RawDataBIDs/composite_phenotypic_file.csv'\n",
    "\n",
    "df_phenotype = pd.read_csv(phenotype_file_path)\n",
    "df_phenotype = df_phenotype.sort_values(['SUB_ID'])\n",
    "df_phenotype_sub_id = df_phenotype.as_matrix(['SITE_ID','SUB_ID']).squeeze()\n",
    "\n",
    "df_demographics = pd.read_csv(demographics_file_path)\n",
    "df_demographics_volumes = df_demographics.as_matrix(['SITE_NAME','VOLUMES']).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_phenotype.sort_values(['SUB_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CALTECH', 150.0],\n",
       "       ['CMU', 240.0],\n",
       "       ['KKI', 156.0],\n",
       "       ['LEUVEN_1', 250.0],\n",
       "       ['LEUVEN_2', 250.0],\n",
       "       ['MAX_MUN', 120.0],\n",
       "       ['NYU', 180.0],\n",
       "       ['OHSU', 82.0],\n",
       "       ['OLIN', 210.0],\n",
       "       ['PITT', 200.0],\n",
       "       ['SBL', 200.0],\n",
       "       ['SDSU', 180.0],\n",
       "       ['STANFORD', 180.0],\n",
       "       ['TRINITY', 150.0],\n",
       "       ['UCLA_1', 120.0],\n",
       "       ['UCLA_2', 120.0],\n",
       "       ['UM_1', 300.0],\n",
       "       ['UM_2', 300.0],\n",
       "       ['USM', 240.0],\n",
       "       ['YALE', 200.0]], dtype=object)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SUB_ID - Volumes Dictionary\n",
    "site_vol_dict = dict(zip(df_demographics_volumes[:,0], df_demographics_volumes[:,1]))\n",
    "\n",
    "# for site_subid in df_demographics_volumes:\n",
    "    \n",
    "\n",
    "# subid_site_dict = dict(zip(df_phenotype_sub_id[:,1], df_phenotype_sub_id[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subid_vol_dict = dict(zip(df_phenotype_sub_id[:,1],[site_vol_dict[site] for site in df_phenotype_sub_id[:,0]] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50002: 200.0,\n",
       " 50003: 200.0,\n",
       " 50004: 200.0,\n",
       " 50005: 200.0,\n",
       " 50006: 200.0,\n",
       " 50007: 200.0,\n",
       " 50008: 200.0,\n",
       " 50009: 200.0,\n",
       " 50010: 200.0,\n",
       " 50011: 200.0,\n",
       " 50012: 200.0,\n",
       " 50013: 200.0,\n",
       " 50014: 200.0,\n",
       " 50015: 200.0,\n",
       " 50016: 200.0,\n",
       " 50017: 200.0,\n",
       " 50019: 200.0,\n",
       " 50020: 200.0,\n",
       " 50022: 200.0,\n",
       " 50023: 200.0,\n",
       " 50024: 200.0,\n",
       " 50025: 200.0,\n",
       " 50026: 200.0,\n",
       " 50027: 200.0,\n",
       " 50028: 200.0,\n",
       " 50029: 200.0,\n",
       " 50030: 200.0,\n",
       " 50031: 200.0,\n",
       " 50032: 200.0,\n",
       " 50033: 200.0,\n",
       " 50034: 200.0,\n",
       " 50035: 200.0,\n",
       " 50036: 200.0,\n",
       " 50037: 200.0,\n",
       " 50038: 200.0,\n",
       " 50039: 200.0,\n",
       " 50040: 200.0,\n",
       " 50041: 200.0,\n",
       " 50042: 200.0,\n",
       " 50043: 200.0,\n",
       " 50044: 200.0,\n",
       " 50045: 200.0,\n",
       " 50046: 200.0,\n",
       " 50047: 200.0,\n",
       " 50048: 200.0,\n",
       " 50049: 200.0,\n",
       " 50050: 200.0,\n",
       " 50051: 200.0,\n",
       " 50052: 200.0,\n",
       " 50053: 200.0,\n",
       " 50054: 200.0,\n",
       " 50055: 200.0,\n",
       " 50056: 200.0,\n",
       " 50057: 200.0,\n",
       " 50058: 200.0,\n",
       " 50059: 200.0,\n",
       " 50060: 200.0,\n",
       " 50102: 210.0,\n",
       " 50103: 210.0,\n",
       " 50104: 210.0,\n",
       " 50105: 210.0,\n",
       " 50106: 210.0,\n",
       " 50107: 210.0,\n",
       " 50108: 210.0,\n",
       " 50109: 210.0,\n",
       " 50110: 210.0,\n",
       " 50111: 210.0,\n",
       " 50112: 210.0,\n",
       " 50113: 210.0,\n",
       " 50114: 210.0,\n",
       " 50115: 210.0,\n",
       " 50116: 210.0,\n",
       " 50117: 210.0,\n",
       " 50118: 210.0,\n",
       " 50119: 210.0,\n",
       " 50120: 210.0,\n",
       " 50121: 210.0,\n",
       " 50122: 210.0,\n",
       " 50123: 210.0,\n",
       " 50124: 210.0,\n",
       " 50125: 210.0,\n",
       " 50126: 210.0,\n",
       " 50127: 210.0,\n",
       " 50128: 210.0,\n",
       " 50129: 210.0,\n",
       " 50130: 210.0,\n",
       " 50131: 210.0,\n",
       " 50132: 210.0,\n",
       " 50133: 210.0,\n",
       " 50134: 210.0,\n",
       " 50135: 210.0,\n",
       " 50136: 210.0,\n",
       " 50137: 210.0,\n",
       " 50142: 82.0,\n",
       " 50143: 82.0,\n",
       " 50144: 82.0,\n",
       " 50145: 82.0,\n",
       " 50146: 82.0,\n",
       " 50147: 82.0,\n",
       " 50148: 82.0,\n",
       " 50149: 82.0,\n",
       " 50150: 82.0,\n",
       " 50152: 82.0,\n",
       " 50153: 82.0,\n",
       " 50155: 82.0,\n",
       " 50156: 82.0,\n",
       " 50157: 82.0,\n",
       " 50158: 82.0,\n",
       " 50159: 82.0,\n",
       " 50160: 82.0,\n",
       " 50161: 82.0,\n",
       " 50162: 82.0,\n",
       " 50163: 82.0,\n",
       " 50164: 82.0,\n",
       " 50165: 82.0,\n",
       " 50166: 82.0,\n",
       " 50167: 82.0,\n",
       " 50168: 82.0,\n",
       " 50169: 82.0,\n",
       " 50170: 82.0,\n",
       " 50171: 82.0,\n",
       " 50182: 180.0,\n",
       " 50183: 180.0,\n",
       " 50184: 180.0,\n",
       " 50185: 180.0,\n",
       " 50186: 180.0,\n",
       " 50187: 180.0,\n",
       " 50188: 180.0,\n",
       " 50189: 180.0,\n",
       " 50190: 180.0,\n",
       " 50191: 180.0,\n",
       " 50192: 180.0,\n",
       " 50193: 180.0,\n",
       " 50194: 180.0,\n",
       " 50195: 180.0,\n",
       " 50196: 180.0,\n",
       " 50197: 180.0,\n",
       " 50198: 180.0,\n",
       " 50199: 180.0,\n",
       " 50200: 180.0,\n",
       " 50201: 180.0,\n",
       " 50202: 180.0,\n",
       " 50203: 180.0,\n",
       " 50204: 180.0,\n",
       " 50205: 180.0,\n",
       " 50206: 180.0,\n",
       " 50207: 180.0,\n",
       " 50208: 180.0,\n",
       " 50209: 180.0,\n",
       " 50210: 180.0,\n",
       " 50211: 180.0,\n",
       " 50212: 180.0,\n",
       " 50213: 180.0,\n",
       " 50214: 180.0,\n",
       " 50215: 180.0,\n",
       " 50216: 180.0,\n",
       " 50217: 180.0,\n",
       " 50232: 150.0,\n",
       " 50233: 150.0,\n",
       " 50234: 150.0,\n",
       " 50235: 150.0,\n",
       " 50236: 150.0,\n",
       " 50237: 150.0,\n",
       " 50238: 150.0,\n",
       " 50239: 150.0,\n",
       " 50240: 150.0,\n",
       " 50241: 150.0,\n",
       " 50242: 150.0,\n",
       " 50243: 150.0,\n",
       " 50244: 150.0,\n",
       " 50245: 150.0,\n",
       " 50246: 150.0,\n",
       " 50247: 150.0,\n",
       " 50248: 150.0,\n",
       " 50249: 150.0,\n",
       " 50250: 150.0,\n",
       " 50251: 150.0,\n",
       " 50252: 150.0,\n",
       " 50253: 150.0,\n",
       " 50254: 150.0,\n",
       " 50255: 150.0,\n",
       " 50257: 150.0,\n",
       " 50259: 150.0,\n",
       " 50260: 150.0,\n",
       " 50261: 150.0,\n",
       " 50262: 150.0,\n",
       " 50263: 150.0,\n",
       " 50264: 150.0,\n",
       " 50265: 150.0,\n",
       " 50266: 150.0,\n",
       " 50267: 150.0,\n",
       " 50268: 150.0,\n",
       " 50269: 150.0,\n",
       " 50270: 150.0,\n",
       " 50271: 150.0,\n",
       " 50272: 300.0,\n",
       " 50273: 300.0,\n",
       " 50274: 300.0,\n",
       " 50275: 300.0,\n",
       " 50276: 300.0,\n",
       " 50277: 300.0,\n",
       " 50278: 300.0,\n",
       " 50279: 300.0,\n",
       " 50280: 300.0,\n",
       " 50281: 300.0,\n",
       " 50282: 300.0,\n",
       " 50283: 300.0,\n",
       " 50284: 300.0,\n",
       " 50285: 300.0,\n",
       " 50286: 300.0,\n",
       " 50287: 300.0,\n",
       " 50288: 300.0,\n",
       " 50289: 300.0,\n",
       " 50290: 300.0,\n",
       " 50291: 300.0,\n",
       " 50292: 300.0,\n",
       " 50293: 300.0,\n",
       " 50294: 300.0,\n",
       " 50295: 300.0,\n",
       " 50296: 300.0,\n",
       " 50297: 300.0,\n",
       " 50298: 300.0,\n",
       " 50299: 300.0,\n",
       " 50300: 300.0,\n",
       " 50301: 300.0,\n",
       " 50302: 300.0,\n",
       " 50303: 300.0,\n",
       " 50304: 300.0,\n",
       " 50305: 300.0,\n",
       " 50306: 300.0,\n",
       " 50307: 300.0,\n",
       " 50308: 300.0,\n",
       " 50309: 300.0,\n",
       " 50310: 300.0,\n",
       " 50311: 300.0,\n",
       " 50312: 300.0,\n",
       " 50313: 300.0,\n",
       " 50314: 300.0,\n",
       " 50315: 300.0,\n",
       " 50316: 300.0,\n",
       " 50317: 300.0,\n",
       " 50318: 300.0,\n",
       " 50319: 300.0,\n",
       " 50320: 300.0,\n",
       " 50321: 300.0,\n",
       " 50322: 300.0,\n",
       " 50323: 300.0,\n",
       " 50324: 300.0,\n",
       " 50325: 300.0,\n",
       " 50326: 300.0,\n",
       " 50327: 300.0,\n",
       " 50328: 300.0,\n",
       " 50329: 300.0,\n",
       " 50330: 300.0,\n",
       " 50331: 300.0,\n",
       " 50332: 300.0,\n",
       " 50333: 300.0,\n",
       " 50334: 300.0,\n",
       " 50335: 300.0,\n",
       " 50336: 300.0,\n",
       " 50337: 300.0,\n",
       " 50338: 300.0,\n",
       " 50339: 300.0,\n",
       " 50340: 300.0,\n",
       " 50341: 300.0,\n",
       " 50342: 300.0,\n",
       " 50343: 300.0,\n",
       " 50344: 300.0,\n",
       " 50345: 300.0,\n",
       " 50346: 300.0,\n",
       " 50347: 300.0,\n",
       " 50348: 300.0,\n",
       " 50349: 300.0,\n",
       " 50350: 300.0,\n",
       " 50351: 300.0,\n",
       " 50352: 300.0,\n",
       " 50353: 300.0,\n",
       " 50354: 300.0,\n",
       " 50355: 300.0,\n",
       " 50356: 300.0,\n",
       " 50357: 300.0,\n",
       " 50358: 300.0,\n",
       " 50359: 300.0,\n",
       " 50360: 300.0,\n",
       " 50361: 300.0,\n",
       " 50362: 300.0,\n",
       " 50363: 300.0,\n",
       " 50364: 300.0,\n",
       " 50365: 300.0,\n",
       " 50366: 300.0,\n",
       " 50367: 300.0,\n",
       " 50368: 300.0,\n",
       " 50369: 300.0,\n",
       " 50370: 300.0,\n",
       " 50371: 300.0,\n",
       " 50372: 300.0,\n",
       " 50373: 300.0,\n",
       " 50374: 300.0,\n",
       " 50375: 300.0,\n",
       " 50376: 300.0,\n",
       " 50377: 300.0,\n",
       " 50378: 300.0,\n",
       " 50379: 300.0,\n",
       " 50380: 300.0,\n",
       " 50381: 300.0,\n",
       " 50382: 300.0,\n",
       " 50383: 300.0,\n",
       " 50385: 300.0,\n",
       " 50386: 300.0,\n",
       " 50387: 300.0,\n",
       " 50388: 300.0,\n",
       " 50390: 300.0,\n",
       " 50391: 300.0,\n",
       " 50397: 300.0,\n",
       " 50399: 300.0,\n",
       " 50402: 300.0,\n",
       " 50403: 300.0,\n",
       " 50404: 300.0,\n",
       " 50405: 300.0,\n",
       " 50406: 300.0,\n",
       " 50407: 300.0,\n",
       " 50408: 300.0,\n",
       " 50410: 300.0,\n",
       " 50411: 300.0,\n",
       " 50412: 300.0,\n",
       " 50413: 300.0,\n",
       " 50414: 300.0,\n",
       " 50415: 300.0,\n",
       " 50416: 300.0,\n",
       " 50417: 300.0,\n",
       " 50418: 300.0,\n",
       " 50419: 300.0,\n",
       " 50421: 300.0,\n",
       " 50422: 300.0,\n",
       " 50423: 300.0,\n",
       " 50424: 300.0,\n",
       " 50425: 300.0,\n",
       " 50426: 300.0,\n",
       " 50427: 300.0,\n",
       " 50428: 300.0,\n",
       " 50432: 240.0,\n",
       " 50433: 240.0,\n",
       " 50434: 240.0,\n",
       " 50435: 240.0,\n",
       " 50436: 240.0,\n",
       " 50437: 240.0,\n",
       " 50438: 240.0,\n",
       " 50439: 240.0,\n",
       " 50440: 240.0,\n",
       " 50441: 240.0,\n",
       " 50442: 240.0,\n",
       " 50443: 240.0,\n",
       " 50444: 240.0,\n",
       " 50445: 240.0,\n",
       " 50446: 240.0,\n",
       " 50447: 240.0,\n",
       " 50448: 240.0,\n",
       " 50449: 240.0,\n",
       " 50450: 240.0,\n",
       " 50451: 240.0,\n",
       " 50452: 240.0,\n",
       " 50453: 240.0,\n",
       " 50454: 240.0,\n",
       " 50455: 240.0,\n",
       " 50456: 240.0,\n",
       " 50457: 240.0,\n",
       " 50458: 240.0,\n",
       " 50459: 240.0,\n",
       " 50460: 240.0,\n",
       " 50461: 240.0,\n",
       " 50462: 240.0,\n",
       " 50463: 240.0,\n",
       " 50464: 240.0,\n",
       " 50465: 240.0,\n",
       " 50466: 240.0,\n",
       " 50467: 240.0,\n",
       " 50468: 240.0,\n",
       " 50469: 240.0,\n",
       " 50470: 240.0,\n",
       " 50471: 240.0,\n",
       " 50472: 240.0,\n",
       " 50473: 240.0,\n",
       " 50474: 240.0,\n",
       " 50475: 240.0,\n",
       " 50476: 240.0,\n",
       " 50477: 240.0,\n",
       " 50478: 240.0,\n",
       " 50479: 240.0,\n",
       " 50480: 240.0,\n",
       " 50481: 240.0,\n",
       " 50482: 240.0,\n",
       " 50483: 240.0,\n",
       " 50484: 240.0,\n",
       " 50485: 240.0,\n",
       " 50486: 240.0,\n",
       " 50487: 240.0,\n",
       " 50488: 240.0,\n",
       " 50489: 240.0,\n",
       " 50490: 240.0,\n",
       " 50491: 240.0,\n",
       " 50492: 240.0,\n",
       " 50493: 240.0,\n",
       " 50494: 240.0,\n",
       " 50495: 240.0,\n",
       " 50496: 240.0,\n",
       " 50497: 240.0,\n",
       " 50498: 240.0,\n",
       " 50499: 240.0,\n",
       " 50500: 240.0,\n",
       " 50501: 240.0,\n",
       " 50502: 240.0,\n",
       " 50503: 240.0,\n",
       " 50504: 240.0,\n",
       " 50505: 240.0,\n",
       " 50506: 240.0,\n",
       " 50507: 240.0,\n",
       " 50508: 240.0,\n",
       " 50509: 240.0,\n",
       " 50510: 240.0,\n",
       " 50511: 240.0,\n",
       " 50512: 240.0,\n",
       " 50513: 240.0,\n",
       " 50514: 240.0,\n",
       " 50515: 240.0,\n",
       " 50516: 240.0,\n",
       " 50517: 240.0,\n",
       " 50518: 240.0,\n",
       " 50519: 240.0,\n",
       " 50520: 240.0,\n",
       " 50521: 240.0,\n",
       " 50522: 240.0,\n",
       " 50523: 240.0,\n",
       " 50524: 240.0,\n",
       " 50525: 240.0,\n",
       " 50526: 240.0,\n",
       " 50527: 240.0,\n",
       " 50528: 240.0,\n",
       " 50529: 240.0,\n",
       " 50530: 240.0,\n",
       " 50531: 240.0,\n",
       " 50532: 240.0,\n",
       " 50551: 200.0,\n",
       " 50552: 200.0,\n",
       " 50553: 200.0,\n",
       " 50554: 200.0,\n",
       " 50555: 200.0,\n",
       " 50556: 200.0,\n",
       " 50557: 200.0,\n",
       " 50558: 200.0,\n",
       " 50559: 200.0,\n",
       " 50560: 200.0,\n",
       " 50561: 200.0,\n",
       " 50562: 200.0,\n",
       " 50563: 200.0,\n",
       " 50564: 200.0,\n",
       " 50565: 200.0,\n",
       " 50566: 200.0,\n",
       " 50567: 200.0,\n",
       " 50568: 200.0,\n",
       " 50569: 200.0,\n",
       " 50570: 200.0,\n",
       " 50571: 200.0,\n",
       " 50572: 200.0,\n",
       " 50573: 200.0,\n",
       " 50574: 200.0,\n",
       " 50575: 200.0,\n",
       " 50576: 200.0,\n",
       " 50577: 200.0,\n",
       " 50578: 200.0,\n",
       " 50601: 200.0,\n",
       " 50602: 200.0,\n",
       " 50603: 200.0,\n",
       " 50604: 200.0,\n",
       " 50605: 200.0,\n",
       " 50606: 200.0,\n",
       " 50607: 200.0,\n",
       " 50608: 200.0,\n",
       " 50609: 200.0,\n",
       " 50610: 200.0,\n",
       " 50611: 200.0,\n",
       " 50612: 200.0,\n",
       " 50613: 200.0,\n",
       " 50614: 200.0,\n",
       " 50615: 200.0,\n",
       " 50616: 200.0,\n",
       " 50617: 200.0,\n",
       " 50618: 200.0,\n",
       " 50619: 200.0,\n",
       " 50620: 200.0,\n",
       " 50621: 200.0,\n",
       " 50622: 200.0,\n",
       " 50623: 200.0,\n",
       " 50624: 200.0,\n",
       " 50625: 200.0,\n",
       " 50626: 200.0,\n",
       " 50627: 200.0,\n",
       " 50628: 200.0,\n",
       " 50642: 240.0,\n",
       " 50643: 240.0,\n",
       " 50644: 240.0,\n",
       " 50645: 240.0,\n",
       " 50646: 240.0,\n",
       " 50647: 240.0,\n",
       " 50648: 240.0,\n",
       " 50649: 240.0,\n",
       " 50650: 240.0,\n",
       " 50651: 240.0,\n",
       " 50652: 240.0,\n",
       " 50653: 240.0,\n",
       " 50654: 240.0,\n",
       " 50655: 240.0,\n",
       " 50656: 240.0,\n",
       " 50657: 240.0,\n",
       " 50658: 240.0,\n",
       " 50659: 240.0,\n",
       " 50660: 240.0,\n",
       " 50661: 240.0,\n",
       " 50663: 240.0,\n",
       " 50664: 240.0,\n",
       " 50665: 240.0,\n",
       " 50666: 240.0,\n",
       " 50667: 240.0,\n",
       " 50668: 240.0,\n",
       " 50669: 240.0,\n",
       " 50682: 250.0,\n",
       " 50683: 250.0,\n",
       " 50685: 250.0,\n",
       " 50686: 250.0,\n",
       " 50687: 250.0,\n",
       " 50688: 250.0,\n",
       " 50689: 250.0,\n",
       " 50690: 250.0,\n",
       " 50691: 250.0,\n",
       " 50692: 250.0,\n",
       " 50693: 250.0,\n",
       " 50694: 250.0,\n",
       " 50695: 250.0,\n",
       " 50696: 250.0,\n",
       " 50697: 250.0,\n",
       " 50698: 250.0,\n",
       " 50699: 250.0,\n",
       " 50700: 250.0,\n",
       " 50701: 250.0,\n",
       " 50702: 250.0,\n",
       " 50703: 250.0,\n",
       " 50704: 250.0,\n",
       " 50705: 250.0,\n",
       " 50706: 250.0,\n",
       " 50707: 250.0,\n",
       " 50708: 250.0,\n",
       " 50709: 250.0,\n",
       " 50710: 250.0,\n",
       " 50711: 250.0,\n",
       " 50722: 250.0,\n",
       " 50723: 250.0,\n",
       " 50724: 250.0,\n",
       " 50725: 250.0,\n",
       " 50726: 250.0,\n",
       " 50727: 250.0,\n",
       " 50728: 250.0,\n",
       " 50730: 250.0,\n",
       " 50731: 250.0,\n",
       " 50732: 250.0,\n",
       " 50733: 250.0,\n",
       " 50734: 250.0,\n",
       " 50735: 250.0,\n",
       " 50736: 250.0,\n",
       " 50737: 250.0,\n",
       " 50738: 250.0,\n",
       " 50739: 250.0,\n",
       " 50740: 250.0,\n",
       " 50741: 250.0,\n",
       " 50742: 250.0,\n",
       " 50743: 250.0,\n",
       " 50744: 250.0,\n",
       " 50745: 250.0,\n",
       " 50746: 250.0,\n",
       " 50747: 250.0,\n",
       " 50748: 250.0,\n",
       " 50749: 250.0,\n",
       " 50750: 250.0,\n",
       " 50751: 250.0,\n",
       " 50752: 250.0,\n",
       " 50753: 250.0,\n",
       " 50754: 250.0,\n",
       " 50755: 250.0,\n",
       " 50756: 250.0,\n",
       " 50757: 250.0,\n",
       " 50772: 156.0,\n",
       " 50773: 156.0,\n",
       " 50774: 156.0,\n",
       " 50775: 156.0,\n",
       " 50776: 156.0,\n",
       " 50777: 156.0,\n",
       " 50778: 156.0,\n",
       " 50779: 156.0,\n",
       " 50780: 156.0,\n",
       " 50781: 156.0,\n",
       " 50782: 156.0,\n",
       " 50783: 156.0,\n",
       " 50784: 156.0,\n",
       " 50785: 156.0,\n",
       " 50786: 156.0,\n",
       " 50787: 156.0,\n",
       " 50788: 156.0,\n",
       " 50789: 156.0,\n",
       " 50790: 156.0,\n",
       " 50791: 156.0,\n",
       " 50792: 156.0,\n",
       " 50793: 156.0,\n",
       " 50794: 156.0,\n",
       " 50795: 156.0,\n",
       " 50796: 156.0,\n",
       " 50797: 156.0,\n",
       " 50798: 156.0,\n",
       " 50799: 156.0,\n",
       " 50800: 156.0,\n",
       " 50801: 156.0,\n",
       " 50802: 156.0,\n",
       " 50803: 156.0,\n",
       " 50804: 156.0,\n",
       " 50805: 156.0,\n",
       " 50806: 156.0,\n",
       " 50807: 156.0,\n",
       " 50808: 156.0,\n",
       " 50809: 156.0,\n",
       " 50810: 156.0,\n",
       " 50811: 156.0,\n",
       " 50812: 156.0,\n",
       " 50813: 156.0,\n",
       " 50814: 156.0,\n",
       " 50815: 156.0,\n",
       " 50816: 156.0,\n",
       " 50817: 156.0,\n",
       " 50818: 156.0,\n",
       " 50819: 156.0,\n",
       " 50820: 156.0,\n",
       " 50821: 156.0,\n",
       " 50822: 156.0,\n",
       " 50823: 156.0,\n",
       " 50824: 156.0,\n",
       " 50825: 156.0,\n",
       " 50826: 156.0,\n",
       " 50952: 180.0,\n",
       " 50953: 180.0,\n",
       " 50954: 180.0,\n",
       " 50955: 180.0,\n",
       " 50956: 180.0,\n",
       " 50957: 180.0,\n",
       " 50958: 180.0,\n",
       " 50959: 180.0,\n",
       " 50960: 180.0,\n",
       " 50961: 180.0,\n",
       " 50962: 180.0,\n",
       " 50964: 180.0,\n",
       " 50965: 180.0,\n",
       " 50966: 180.0,\n",
       " 50967: 180.0,\n",
       " 50968: 180.0,\n",
       " 50969: 180.0,\n",
       " 50970: 180.0,\n",
       " 50971: 180.0,\n",
       " 50972: 180.0,\n",
       " 50973: 180.0,\n",
       " 50974: 180.0,\n",
       " 50975: 180.0,\n",
       " 50976: 180.0,\n",
       " 50977: 180.0,\n",
       " 50978: 180.0,\n",
       " 50979: 180.0,\n",
       " 50980: 180.0,\n",
       " 50981: 180.0,\n",
       " 50982: 180.0,\n",
       " 50983: 180.0,\n",
       " 50984: 180.0,\n",
       " 50985: 180.0,\n",
       " 50986: 180.0,\n",
       " 50987: 180.0,\n",
       " 50988: 180.0,\n",
       " 50989: 180.0,\n",
       " 50990: 180.0,\n",
       " 50991: 180.0,\n",
       " 50992: 180.0,\n",
       " 50993: 180.0,\n",
       " 50994: 180.0,\n",
       " 50995: 180.0,\n",
       " 50996: 180.0,\n",
       " 50997: 180.0,\n",
       " 50998: 180.0,\n",
       " 50999: 180.0,\n",
       " 51000: 180.0,\n",
       " 51001: 180.0,\n",
       " 51002: 180.0,\n",
       " 51003: 180.0,\n",
       " 51006: 180.0,\n",
       " 51007: 180.0,\n",
       " 51008: 180.0,\n",
       " 51009: 180.0,\n",
       " 51010: 180.0,\n",
       " 51011: 180.0,\n",
       " 51012: 180.0,\n",
       " 51013: 180.0,\n",
       " 51014: 180.0,\n",
       " 51015: 180.0,\n",
       " 51016: 180.0,\n",
       " 51017: 180.0,\n",
       " 51018: 180.0,\n",
       " 51019: 180.0,\n",
       " 51020: 180.0,\n",
       " 51021: 180.0,\n",
       " 51023: 180.0,\n",
       " 51024: 180.0,\n",
       " 51025: 180.0,\n",
       " 51026: 180.0,\n",
       " 51027: 180.0,\n",
       " 51028: 180.0,\n",
       " 51029: 180.0,\n",
       " 51030: 180.0,\n",
       " 51032: 180.0,\n",
       " 51033: 180.0,\n",
       " 51034: 180.0,\n",
       " 51035: 180.0,\n",
       " 51036: 180.0,\n",
       " 51038: 180.0,\n",
       " 51039: 180.0,\n",
       " 51040: 180.0,\n",
       " 51041: 180.0,\n",
       " 51042: 180.0,\n",
       " 51044: 180.0,\n",
       " 51045: 180.0,\n",
       " 51046: 180.0,\n",
       " 51047: 180.0,\n",
       " 51048: 180.0,\n",
       " 51049: 180.0,\n",
       " 51050: 180.0,\n",
       " 51051: 180.0,\n",
       " 51052: 180.0,\n",
       " 51053: 180.0,\n",
       " 51054: 180.0,\n",
       " 51055: 180.0,\n",
       " 51056: 180.0,\n",
       " 51057: 180.0,\n",
       " 51058: 180.0,\n",
       " 51059: 180.0,\n",
       " 51060: 180.0,\n",
       " 51061: 180.0,\n",
       " 51062: 180.0,\n",
       " 51063: 180.0,\n",
       " 51064: 180.0,\n",
       " 51065: 180.0,\n",
       " 51066: 180.0,\n",
       " 51067: 180.0,\n",
       " 51068: 180.0,\n",
       " 51069: 180.0,\n",
       " 51070: 180.0,\n",
       " 51071: 180.0,\n",
       " 51072: 180.0,\n",
       " 51073: 180.0,\n",
       " 51074: 180.0,\n",
       " 51075: 180.0,\n",
       " 51076: 180.0,\n",
       " 51077: 180.0,\n",
       " 51078: 180.0,\n",
       " 51079: 180.0,\n",
       " 51080: 180.0,\n",
       " 51081: 180.0,\n",
       " 51082: 180.0,\n",
       " 51083: 180.0,\n",
       " 51084: 180.0,\n",
       " 51085: 180.0,\n",
       " 51086: 180.0,\n",
       " 51087: 180.0,\n",
       " 51088: 180.0,\n",
       " 51089: 180.0,\n",
       " 51090: 180.0,\n",
       " 51091: 180.0,\n",
       " 51093: 180.0,\n",
       " 51094: 180.0,\n",
       " 51095: 180.0,\n",
       " 51096: 180.0,\n",
       " 51097: 180.0,\n",
       " 51098: 180.0,\n",
       " 51099: 180.0,\n",
       " 51100: 180.0,\n",
       " 51101: 180.0,\n",
       " 51102: 180.0,\n",
       " 51103: 180.0,\n",
       " 51104: 180.0,\n",
       " 51105: 180.0,\n",
       " 51106: 180.0,\n",
       " 51107: 180.0,\n",
       " 51108: 180.0,\n",
       " 51109: 180.0,\n",
       " 51110: 180.0,\n",
       " 51111: 180.0,\n",
       " 51112: 180.0,\n",
       " 51113: 180.0,\n",
       " 51114: 180.0,\n",
       " 51115: 180.0,\n",
       " 51116: 180.0,\n",
       " 51117: 180.0,\n",
       " 51118: 180.0,\n",
       " 51119: 180.0,\n",
       " 51120: 180.0,\n",
       " 51121: 180.0,\n",
       " 51122: 180.0,\n",
       " 51123: 180.0,\n",
       " 51124: 180.0,\n",
       " 51125: 180.0,\n",
       " 51126: 180.0,\n",
       " 51127: 180.0,\n",
       " 51128: 180.0,\n",
       " 51129: 180.0,\n",
       " 51130: 180.0,\n",
       " 51131: 180.0,\n",
       " 51132: 150.0,\n",
       " 51133: 150.0,\n",
       " 51134: 150.0,\n",
       " 51135: 150.0,\n",
       " 51136: 150.0,\n",
       " 51137: 150.0,\n",
       " 51138: 150.0,\n",
       " 51139: 150.0,\n",
       " 51140: 150.0,\n",
       " 51141: 150.0,\n",
       " 51142: 150.0,\n",
       " 51146: 180.0,\n",
       " 51147: 180.0,\n",
       " 51148: 180.0,\n",
       " 51149: 180.0,\n",
       " 51150: 180.0,\n",
       " 51151: 180.0,\n",
       " 51152: 180.0,\n",
       " 51153: 180.0,\n",
       " 51154: 180.0,\n",
       " 51155: 180.0,\n",
       " 51156: 180.0,\n",
       " 51159: 180.0,\n",
       " 51160: 180.0,\n",
       " 51161: 180.0,\n",
       " 51162: 180.0,\n",
       " 51163: 180.0,\n",
       " 51164: 180.0,\n",
       " 51165: 180.0,\n",
       " 51166: 180.0,\n",
       " 51167: 180.0,\n",
       " 51168: 180.0,\n",
       " 51169: 180.0,\n",
       " 51170: 180.0,\n",
       " 51171: 180.0,\n",
       " 51172: 180.0,\n",
       " 51173: 180.0,\n",
       " 51174: 180.0,\n",
       " 51175: 180.0,\n",
       " 51176: 180.0,\n",
       " 51177: 180.0,\n",
       " 51178: 180.0,\n",
       " 51179: 180.0,\n",
       " 51180: 180.0,\n",
       " 51181: 180.0,\n",
       " 51182: 180.0,\n",
       " 51183: 180.0,\n",
       " 51184: 180.0,\n",
       " 51185: 180.0,\n",
       " 51186: 180.0,\n",
       " 51187: 180.0,\n",
       " 51188: 180.0,\n",
       " 51189: 180.0,\n",
       " 51190: 180.0,\n",
       " 51191: 180.0,\n",
       " 51192: 180.0,\n",
       " 51193: 180.0,\n",
       " 51194: 180.0,\n",
       " 51195: 180.0,\n",
       " 51196: 180.0,\n",
       " 51197: 180.0,\n",
       " 51198: 180.0,\n",
       " 51199: 180.0,\n",
       " 51201: 120.0,\n",
       " 51202: 120.0,\n",
       " 51203: 120.0,\n",
       " 51204: 120.0,\n",
       " 51205: 120.0,\n",
       " 51206: 120.0,\n",
       " 51207: 120.0,\n",
       " 51208: 120.0,\n",
       " 51209: 120.0,\n",
       " 51210: 120.0,\n",
       " 51211: 120.0,\n",
       " 51212: 120.0,\n",
       " 51213: 120.0,\n",
       " 51214: 120.0,\n",
       " 51215: 120.0,\n",
       " 51216: 120.0,\n",
       " 51217: 120.0,\n",
       " 51218: 120.0,\n",
       " 51219: 120.0,\n",
       " 51220: 120.0,\n",
       " 51221: 120.0,\n",
       " 51222: 120.0,\n",
       " 51223: 120.0,\n",
       " 51224: 120.0,\n",
       " 51225: 120.0,\n",
       " 51226: 120.0,\n",
       " 51227: 120.0,\n",
       " 51228: 120.0,\n",
       " 51229: 120.0,\n",
       " 51230: 120.0,\n",
       " 51231: 120.0,\n",
       " 51232: 120.0,\n",
       " 51233: 120.0,\n",
       " 51234: 120.0,\n",
       " 51235: 120.0,\n",
       " 51236: 120.0,\n",
       " 51237: 120.0,\n",
       " 51238: 120.0,\n",
       " 51239: 120.0,\n",
       " 51240: 120.0,\n",
       " 51241: 120.0,\n",
       " 51242: 120.0,\n",
       " 51243: 120.0,\n",
       " 51244: 120.0,\n",
       " 51245: 120.0,\n",
       " 51246: 120.0,\n",
       " 51247: 120.0,\n",
       " 51248: 120.0,\n",
       " 51249: 120.0,\n",
       " 51250: 120.0,\n",
       " 51251: 120.0,\n",
       " 51252: 120.0,\n",
       " 51253: 120.0,\n",
       " 51254: 120.0,\n",
       " 51255: 120.0,\n",
       " 51256: 120.0,\n",
       " 51257: 120.0,\n",
       " 51258: 120.0,\n",
       " 51259: 120.0,\n",
       " 51260: 120.0,\n",
       " 51261: 120.0,\n",
       " 51262: 120.0,\n",
       " 51263: 120.0,\n",
       " 51264: 120.0,\n",
       " 51265: 120.0,\n",
       " 51266: 120.0,\n",
       " 51267: 120.0,\n",
       " 51268: 120.0,\n",
       " 51269: 120.0,\n",
       " 51270: 120.0,\n",
       " 51271: 120.0,\n",
       " 51272: 120.0,\n",
       " 51273: 120.0,\n",
       " 51274: 120.0,\n",
       " 51275: 120.0,\n",
       " 51276: 120.0,\n",
       " 51277: 120.0,\n",
       " 51278: 120.0,\n",
       " 51279: 120.0,\n",
       " 51280: 120.0,\n",
       " 51281: 120.0,\n",
       " 51282: 120.0,\n",
       " 51291: 120.0,\n",
       " 51292: 120.0,\n",
       " 51293: 120.0,\n",
       " 51294: 120.0,\n",
       " 51295: 120.0,\n",
       " 51296: 120.0,\n",
       " 51297: 120.0,\n",
       " 51298: 120.0,\n",
       " 51299: 120.0,\n",
       " 51300: 120.0,\n",
       " 51301: 120.0,\n",
       " 51302: 120.0,\n",
       " 51303: 120.0,\n",
       " 51304: 120.0,\n",
       " 51305: 120.0,\n",
       " 51306: 120.0,\n",
       " 51307: 120.0,\n",
       " 51308: 120.0,\n",
       " 51309: 120.0,\n",
       " 51310: 120.0,\n",
       " 51311: 120.0,\n",
       " 51312: 120.0,\n",
       " 51313: 120.0,\n",
       " 51314: 120.0,\n",
       " 51315: 120.0,\n",
       " 51316: 120.0,\n",
       " 51317: 120.0,\n",
       " 51318: 120.0,\n",
       " 51319: 120.0,\n",
       " 51320: 120.0,\n",
       " 51321: 120.0,\n",
       " 51322: 120.0,\n",
       " 51323: 120.0,\n",
       " 51324: 120.0,\n",
       " 51325: 120.0,\n",
       " 51326: 120.0,\n",
       " 51327: 120.0,\n",
       " 51328: 120.0,\n",
       " 51329: 120.0,\n",
       " 51330: 120.0,\n",
       " ...}"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subid_vol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vols = 120\n",
    "del_idx = []\n",
    "for idx,df in enumerate(df_demographics_volumes):\n",
    "#     print(idx,df[1])\n",
    "    if df[1] < vols:\n",
    "        del_idx.append(idx)\n",
    "        \n",
    "df_demographics_volumes = np.delete(df_demographics_volumes,del_idx, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_demographics_sites_refined = df_demographics_volumes[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CALTECH', 'CMU', 'KKI', 'LEUVEN_1', 'LEUVEN_2', 'MAX_MUN', 'NYU',\n",
       "       'OLIN', 'PITT', 'SBL', 'SDSU', 'STANFORD', 'TRINITY', 'UCLA_1',\n",
       "       'UCLA_2', 'UM_1', 'UM_2', 'USM', 'YALE'], dtype=object)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics_sites_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['PITT', 50002],\n",
       "       ['PITT', 50003],\n",
       "       ['PITT', 50004],\n",
       "       ..., \n",
       "       ['SBL', 51585],\n",
       "       ['MAX_MUN', 51606],\n",
       "       ['MAX_MUN', 51607]], dtype=object)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phenotype_sub_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject IDs to be considered - \n",
    "```subjects_refined```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects_refined = []\n",
    "for df in df_phenotype_sub_id:\n",
    "    if df[0] in df_demographics_sites_refined:\n",
    "#         print(df[1])\n",
    "        subjects_refined.append(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects_refined = list(set(subjects_refined) - (set(df_phenotype_sub_id[:,1]) - set(subject_list) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50002,\n",
       " 50003,\n",
       " 50004,\n",
       " 50005,\n",
       " 50006,\n",
       " 50007,\n",
       " 50008,\n",
       " 50009,\n",
       " 50010,\n",
       " 50011,\n",
       " 50012,\n",
       " 50013,\n",
       " 50014,\n",
       " 50015,\n",
       " 50016,\n",
       " 50017,\n",
       " 50019,\n",
       " 50020,\n",
       " 50022,\n",
       " 50023,\n",
       " 50024,\n",
       " 50025,\n",
       " 50026,\n",
       " 50027,\n",
       " 50028,\n",
       " 50029,\n",
       " 50030,\n",
       " 50031,\n",
       " 50032,\n",
       " 50033,\n",
       " 50034,\n",
       " 50035,\n",
       " 50036,\n",
       " 50037,\n",
       " 50038,\n",
       " 50039,\n",
       " 50040,\n",
       " 50041,\n",
       " 50042,\n",
       " 50043,\n",
       " 50044,\n",
       " 50045,\n",
       " 50046,\n",
       " 50047,\n",
       " 50048,\n",
       " 50049,\n",
       " 50050,\n",
       " 50051,\n",
       " 50052,\n",
       " 50053,\n",
       " 50054,\n",
       " 50055,\n",
       " 50056,\n",
       " 50057,\n",
       " 50058,\n",
       " 50059,\n",
       " 50060,\n",
       " 50102,\n",
       " 50103,\n",
       " 50104,\n",
       " 50105,\n",
       " 50106,\n",
       " 50107,\n",
       " 50108,\n",
       " 50109,\n",
       " 50110,\n",
       " 50111,\n",
       " 50112,\n",
       " 50113,\n",
       " 50114,\n",
       " 50115,\n",
       " 50116,\n",
       " 50117,\n",
       " 50118,\n",
       " 50119,\n",
       " 50120,\n",
       " 50121,\n",
       " 50122,\n",
       " 50123,\n",
       " 50124,\n",
       " 50125,\n",
       " 50126,\n",
       " 50127,\n",
       " 50128,\n",
       " 50129,\n",
       " 50130,\n",
       " 50131,\n",
       " 50132,\n",
       " 50133,\n",
       " 50134,\n",
       " 50135,\n",
       " 50136,\n",
       " 50137,\n",
       " 50142,\n",
       " 50143,\n",
       " 50144,\n",
       " 50145,\n",
       " 50146,\n",
       " 50147,\n",
       " 50148,\n",
       " 50149,\n",
       " 50150,\n",
       " 50152,\n",
       " 50153,\n",
       " 50155,\n",
       " 50156,\n",
       " 50157,\n",
       " 50158,\n",
       " 50159,\n",
       " 50160,\n",
       " 50161,\n",
       " 50162,\n",
       " 50163,\n",
       " 50164,\n",
       " 50165,\n",
       " 50166,\n",
       " 50167,\n",
       " 50168,\n",
       " 50169,\n",
       " 50170,\n",
       " 50171,\n",
       " 50182,\n",
       " 50183,\n",
       " 50184,\n",
       " 50185,\n",
       " 50186,\n",
       " 50187,\n",
       " 50188,\n",
       " 50189,\n",
       " 50190,\n",
       " 50191,\n",
       " 50192,\n",
       " 50193,\n",
       " 50194,\n",
       " 50195,\n",
       " 50196,\n",
       " 50197,\n",
       " 50198,\n",
       " 50199,\n",
       " 50200,\n",
       " 50201,\n",
       " 50202,\n",
       " 50203,\n",
       " 50204,\n",
       " 50205,\n",
       " 50206,\n",
       " 50207,\n",
       " 50208,\n",
       " 50209,\n",
       " 50210,\n",
       " 50211,\n",
       " 50212,\n",
       " 50213,\n",
       " 50214,\n",
       " 50215,\n",
       " 50216,\n",
       " 50217,\n",
       " 50232,\n",
       " 50233,\n",
       " 50234,\n",
       " 50235,\n",
       " 50236,\n",
       " 50237,\n",
       " 50238,\n",
       " 50239,\n",
       " 50240,\n",
       " 50241,\n",
       " 50242,\n",
       " 50243,\n",
       " 50244,\n",
       " 50245,\n",
       " 50246,\n",
       " 50247,\n",
       " 50248,\n",
       " 50249,\n",
       " 50250,\n",
       " 50251,\n",
       " 50252,\n",
       " 50253,\n",
       " 50254,\n",
       " 50255,\n",
       " 50257,\n",
       " 50259,\n",
       " 50260,\n",
       " 50261,\n",
       " 50262,\n",
       " 50263,\n",
       " 50264,\n",
       " 50265,\n",
       " 50266,\n",
       " 50267,\n",
       " 50268,\n",
       " 50269,\n",
       " 50270,\n",
       " 50271,\n",
       " 50272,\n",
       " 50273,\n",
       " 50274,\n",
       " 50275,\n",
       " 50276,\n",
       " 50277,\n",
       " 50278,\n",
       " 50279,\n",
       " 50280,\n",
       " 50281,\n",
       " 50282,\n",
       " 50283,\n",
       " 50284,\n",
       " 50285,\n",
       " 50286,\n",
       " 50287,\n",
       " 50288,\n",
       " 50289,\n",
       " 50290,\n",
       " 50291,\n",
       " 50292,\n",
       " 50293,\n",
       " 50294,\n",
       " 50295,\n",
       " 50296,\n",
       " 50297,\n",
       " 50298,\n",
       " 50299,\n",
       " 50300,\n",
       " 50301,\n",
       " 50302,\n",
       " 50303,\n",
       " 50304,\n",
       " 50305,\n",
       " 50306,\n",
       " 50307,\n",
       " 50308,\n",
       " 50309,\n",
       " 50310,\n",
       " 50311,\n",
       " 50312,\n",
       " 50313,\n",
       " 50314,\n",
       " 50315,\n",
       " 50316,\n",
       " 50317,\n",
       " 50318,\n",
       " 50319,\n",
       " 50320,\n",
       " 50321,\n",
       " 50322,\n",
       " 50323,\n",
       " 50324,\n",
       " 50325,\n",
       " 50326,\n",
       " 50327,\n",
       " 50328,\n",
       " 50329,\n",
       " 50330,\n",
       " 50331,\n",
       " 50332,\n",
       " 50333,\n",
       " 50334,\n",
       " 50335,\n",
       " 50336,\n",
       " 50337,\n",
       " 50338,\n",
       " 50339,\n",
       " 50340,\n",
       " 50341,\n",
       " 50342,\n",
       " 50343,\n",
       " 50344,\n",
       " 50345,\n",
       " 50346,\n",
       " 50347,\n",
       " 50348,\n",
       " 50349,\n",
       " 50350,\n",
       " 50351,\n",
       " 50352,\n",
       " 50353,\n",
       " 50354,\n",
       " 50355,\n",
       " 50356,\n",
       " 50357,\n",
       " 50358,\n",
       " 50359,\n",
       " 50360,\n",
       " 50361,\n",
       " 50362,\n",
       " 50363,\n",
       " 50364,\n",
       " 50365,\n",
       " 50366,\n",
       " 50367,\n",
       " 50368,\n",
       " 50369,\n",
       " 50370,\n",
       " 50371,\n",
       " 50372,\n",
       " 50373,\n",
       " 50374,\n",
       " 50375,\n",
       " 50376,\n",
       " 50377,\n",
       " 50378,\n",
       " 50379,\n",
       " 50380,\n",
       " 50381,\n",
       " 50382,\n",
       " 50383,\n",
       " 50385,\n",
       " 50386,\n",
       " 50387,\n",
       " 50388,\n",
       " 50390,\n",
       " 50391,\n",
       " 50397,\n",
       " 50399,\n",
       " 50402,\n",
       " 50403,\n",
       " 50404,\n",
       " 50405,\n",
       " 50406,\n",
       " 50407,\n",
       " 50408,\n",
       " 50410,\n",
       " 50411,\n",
       " 50412,\n",
       " 50413,\n",
       " 50414,\n",
       " 50415,\n",
       " 50416,\n",
       " 50417,\n",
       " 50418,\n",
       " 50419,\n",
       " 50421,\n",
       " 50422,\n",
       " 50423,\n",
       " 50424,\n",
       " 50425,\n",
       " 50426,\n",
       " 50427,\n",
       " 50428,\n",
       " 50432,\n",
       " 50433,\n",
       " 50434,\n",
       " 50435,\n",
       " 50436,\n",
       " 50437,\n",
       " 50438,\n",
       " 50439,\n",
       " 50440,\n",
       " 50441,\n",
       " 50442,\n",
       " 50443,\n",
       " 50444,\n",
       " 50445,\n",
       " 50446,\n",
       " 50447,\n",
       " 50448,\n",
       " 50449,\n",
       " 50450,\n",
       " 50451,\n",
       " 50452,\n",
       " 50453,\n",
       " 50454,\n",
       " 50455,\n",
       " 50456,\n",
       " 50457,\n",
       " 50458,\n",
       " 50459,\n",
       " 50460,\n",
       " 50461,\n",
       " 50462,\n",
       " 50463,\n",
       " 50464,\n",
       " 50465,\n",
       " 50466,\n",
       " 50467,\n",
       " 50468,\n",
       " 50469,\n",
       " 50470,\n",
       " 50471,\n",
       " 50472,\n",
       " 50473,\n",
       " 50474,\n",
       " 50475,\n",
       " 50476,\n",
       " 50477,\n",
       " 50478,\n",
       " 50479,\n",
       " 50480,\n",
       " 50481,\n",
       " 50482,\n",
       " 50483,\n",
       " 50484,\n",
       " 50485,\n",
       " 50486,\n",
       " 50487,\n",
       " 50488,\n",
       " 50489,\n",
       " 50490,\n",
       " 50491,\n",
       " 50492,\n",
       " 50493,\n",
       " 50494,\n",
       " 50495,\n",
       " 50496,\n",
       " 50497,\n",
       " 50498,\n",
       " 50499,\n",
       " 50500,\n",
       " 50501,\n",
       " 50502,\n",
       " 50503,\n",
       " 50504,\n",
       " 50505,\n",
       " 50506,\n",
       " 50507,\n",
       " 50508,\n",
       " 50509,\n",
       " 50510,\n",
       " 50511,\n",
       " 50512,\n",
       " 50513,\n",
       " 50514,\n",
       " 50515,\n",
       " 50516,\n",
       " 50517,\n",
       " 50518,\n",
       " 50519,\n",
       " 50520,\n",
       " 50521,\n",
       " 50522,\n",
       " 50523,\n",
       " 50524,\n",
       " 50525,\n",
       " 50526,\n",
       " 50527,\n",
       " 50528,\n",
       " 50529,\n",
       " 50530,\n",
       " 50531,\n",
       " 50532,\n",
       " 50551,\n",
       " 50552,\n",
       " 50553,\n",
       " 50554,\n",
       " 50555,\n",
       " 50556,\n",
       " 50557,\n",
       " 50558,\n",
       " 50559,\n",
       " 50560,\n",
       " 50561,\n",
       " 50562,\n",
       " 50563,\n",
       " 50564,\n",
       " 50565,\n",
       " 50566,\n",
       " 50567,\n",
       " 50568,\n",
       " 50569,\n",
       " 50570,\n",
       " 50571,\n",
       " 50572,\n",
       " 50573,\n",
       " 50574,\n",
       " 50575,\n",
       " 50576,\n",
       " 50577,\n",
       " 50578,\n",
       " 50601,\n",
       " 50602,\n",
       " 50603,\n",
       " 50604,\n",
       " 50605,\n",
       " 50606,\n",
       " 50607,\n",
       " 50608,\n",
       " 50609,\n",
       " 50610,\n",
       " 50611,\n",
       " 50612,\n",
       " 50613,\n",
       " 50614,\n",
       " 50615,\n",
       " 50616,\n",
       " 50617,\n",
       " 50618,\n",
       " 50619,\n",
       " 50620,\n",
       " 50621,\n",
       " 50622,\n",
       " 50623,\n",
       " 50624,\n",
       " 50625,\n",
       " 50626,\n",
       " 50627,\n",
       " 50628,\n",
       " 50642,\n",
       " 50643,\n",
       " 50644,\n",
       " 50645,\n",
       " 50646,\n",
       " 50647,\n",
       " 50648,\n",
       " 50649,\n",
       " 50650,\n",
       " 50651,\n",
       " 50652,\n",
       " 50653,\n",
       " 50654,\n",
       " 50655,\n",
       " 50656,\n",
       " 50657,\n",
       " 50658,\n",
       " 50659,\n",
       " 50660,\n",
       " 50661,\n",
       " 50663,\n",
       " 50664,\n",
       " 50665,\n",
       " 50666,\n",
       " 50667,\n",
       " 50668,\n",
       " 50669,\n",
       " 50682,\n",
       " 50683,\n",
       " 50685,\n",
       " 50686,\n",
       " 50687,\n",
       " 50688,\n",
       " 50689,\n",
       " 50690,\n",
       " 50691,\n",
       " 50692,\n",
       " 50693,\n",
       " 50694,\n",
       " 50695,\n",
       " 50696,\n",
       " 50697,\n",
       " 50698,\n",
       " 50699,\n",
       " 50700,\n",
       " 50701,\n",
       " 50702,\n",
       " 50703,\n",
       " 50704,\n",
       " 50705,\n",
       " 50706,\n",
       " 50707,\n",
       " 50708,\n",
       " 50709,\n",
       " 50710,\n",
       " 50711,\n",
       " 50722,\n",
       " 50723,\n",
       " 50724,\n",
       " 50725,\n",
       " 50726,\n",
       " 50727,\n",
       " 50728,\n",
       " 50730,\n",
       " 50731,\n",
       " 50732,\n",
       " 50733,\n",
       " 50734,\n",
       " 50735,\n",
       " 50736,\n",
       " 50737,\n",
       " 50738,\n",
       " 50739,\n",
       " 50740,\n",
       " 50741,\n",
       " 50742,\n",
       " 50743,\n",
       " 50744,\n",
       " 50745,\n",
       " 50746,\n",
       " 50747,\n",
       " 50748,\n",
       " 50749,\n",
       " 50750,\n",
       " 50751,\n",
       " 50752,\n",
       " 50753,\n",
       " 50754,\n",
       " 50755,\n",
       " 50756,\n",
       " 50757,\n",
       " 50772,\n",
       " 50773,\n",
       " 50774,\n",
       " 50775,\n",
       " 50776,\n",
       " 50777,\n",
       " 50778,\n",
       " 50779,\n",
       " 50780,\n",
       " 50781,\n",
       " 50782,\n",
       " 50783,\n",
       " 50784,\n",
       " 50785,\n",
       " 50786,\n",
       " 50787,\n",
       " 50788,\n",
       " 50789,\n",
       " 50790,\n",
       " 50791,\n",
       " 50792,\n",
       " 50793,\n",
       " 50794,\n",
       " 50795,\n",
       " 50796,\n",
       " 50797,\n",
       " 50798,\n",
       " 50799,\n",
       " 50800,\n",
       " 50801,\n",
       " 50802,\n",
       " 50803,\n",
       " 50804,\n",
       " 50805,\n",
       " 50806,\n",
       " 50807,\n",
       " 50808,\n",
       " 50809,\n",
       " 50810,\n",
       " 50811,\n",
       " 50812,\n",
       " 50813,\n",
       " 50814,\n",
       " 50815,\n",
       " 50816,\n",
       " 50817,\n",
       " 50818,\n",
       " 50819,\n",
       " 50820,\n",
       " 50821,\n",
       " 50822,\n",
       " 50823,\n",
       " 50824,\n",
       " 50825,\n",
       " 50826,\n",
       " 50952,\n",
       " 50953,\n",
       " 50954,\n",
       " 50955,\n",
       " 50956,\n",
       " 50957,\n",
       " 50958,\n",
       " 50959,\n",
       " 50960,\n",
       " 50961,\n",
       " 50962,\n",
       " 50964,\n",
       " 50965,\n",
       " 50966,\n",
       " 50967,\n",
       " 50968,\n",
       " 50969,\n",
       " 50970,\n",
       " 50971,\n",
       " 50972,\n",
       " 50973,\n",
       " 50974,\n",
       " 50975,\n",
       " 50976,\n",
       " 50977,\n",
       " 50978,\n",
       " 50979,\n",
       " 50980,\n",
       " 50981,\n",
       " 50982,\n",
       " 50983,\n",
       " 50984,\n",
       " 50985,\n",
       " 50986,\n",
       " 50987,\n",
       " 50988,\n",
       " 50989,\n",
       " 50990,\n",
       " 50991,\n",
       " 50992,\n",
       " 50993,\n",
       " 50994,\n",
       " 50995,\n",
       " 50996,\n",
       " 50997,\n",
       " 50998,\n",
       " 50999,\n",
       " 51000,\n",
       " 51001,\n",
       " 51002,\n",
       " 51003,\n",
       " 51006,\n",
       " 51007,\n",
       " 51008,\n",
       " 51009,\n",
       " 51010,\n",
       " 51011,\n",
       " 51012,\n",
       " 51013,\n",
       " 51014,\n",
       " 51015,\n",
       " 51016,\n",
       " 51017,\n",
       " 51018,\n",
       " 51019,\n",
       " 51020,\n",
       " 51021,\n",
       " 51023,\n",
       " 51024,\n",
       " 51025,\n",
       " 51026,\n",
       " 51027,\n",
       " 51028,\n",
       " 51029,\n",
       " 51030,\n",
       " 51032,\n",
       " 51033,\n",
       " 51034,\n",
       " 51035,\n",
       " 51036,\n",
       " 51038,\n",
       " 51039,\n",
       " 51040,\n",
       " 51041,\n",
       " 51042,\n",
       " 51044,\n",
       " 51045,\n",
       " 51046,\n",
       " 51047,\n",
       " 51048,\n",
       " 51049,\n",
       " 51050,\n",
       " 51051,\n",
       " 51052,\n",
       " 51053,\n",
       " 51054,\n",
       " 51055,\n",
       " 51056,\n",
       " 51057,\n",
       " 51058,\n",
       " 51059,\n",
       " 51060,\n",
       " 51061,\n",
       " 51062,\n",
       " 51063,\n",
       " 51064,\n",
       " 51065,\n",
       " 51066,\n",
       " 51067,\n",
       " 51068,\n",
       " 51069,\n",
       " 51070,\n",
       " 51071,\n",
       " 51072,\n",
       " 51073,\n",
       " 51074,\n",
       " 51075,\n",
       " 51076,\n",
       " 51077,\n",
       " 51078,\n",
       " 51079,\n",
       " 51080,\n",
       " 51081,\n",
       " 51082,\n",
       " 51083,\n",
       " 51084,\n",
       " 51085,\n",
       " 51086,\n",
       " 51087,\n",
       " 51088,\n",
       " 51089,\n",
       " 51090,\n",
       " 51091,\n",
       " 51093,\n",
       " 51094,\n",
       " 51095,\n",
       " 51096,\n",
       " 51097,\n",
       " 51098,\n",
       " 51099,\n",
       " 51100,\n",
       " 51101,\n",
       " 51102,\n",
       " 51103,\n",
       " 51104,\n",
       " 51105,\n",
       " 51106,\n",
       " 51107,\n",
       " 51108,\n",
       " 51109,\n",
       " 51110,\n",
       " 51111,\n",
       " 51112,\n",
       " 51113,\n",
       " 51114,\n",
       " 51115,\n",
       " 51116,\n",
       " 51117,\n",
       " 51118,\n",
       " 51119,\n",
       " 51120,\n",
       " 51121,\n",
       " 51122,\n",
       " 51123,\n",
       " 51124,\n",
       " 51125,\n",
       " 51126,\n",
       " 51127,\n",
       " 51128,\n",
       " 51129,\n",
       " 51130,\n",
       " 51131,\n",
       " 51132,\n",
       " 51133,\n",
       " 51134,\n",
       " 51135,\n",
       " 51136,\n",
       " 51137,\n",
       " 51138,\n",
       " 51139,\n",
       " 51140,\n",
       " 51141,\n",
       " 51142,\n",
       " 51146,\n",
       " 51147,\n",
       " 51148,\n",
       " 51149,\n",
       " 51150,\n",
       " 51151,\n",
       " 51152,\n",
       " 51153,\n",
       " 51154,\n",
       " 51155,\n",
       " 51156,\n",
       " 51159,\n",
       " 51160,\n",
       " 51161,\n",
       " 51162,\n",
       " 51163,\n",
       " 51164,\n",
       " 51165,\n",
       " 51166,\n",
       " 51167,\n",
       " 51168,\n",
       " 51169,\n",
       " 51170,\n",
       " 51171,\n",
       " 51172,\n",
       " 51173,\n",
       " 51174,\n",
       " 51175,\n",
       " 51176,\n",
       " 51177,\n",
       " 51178,\n",
       " 51179,\n",
       " 51180,\n",
       " 51181,\n",
       " 51182,\n",
       " 51183,\n",
       " 51184,\n",
       " 51185,\n",
       " 51186,\n",
       " 51187,\n",
       " 51188,\n",
       " 51189,\n",
       " 51190,\n",
       " 51191,\n",
       " 51192,\n",
       " 51193,\n",
       " 51194,\n",
       " 51195,\n",
       " 51196,\n",
       " 51197,\n",
       " 51198,\n",
       " 51199,\n",
       " 51201,\n",
       " 51202,\n",
       " 51203,\n",
       " 51204,\n",
       " 51205,\n",
       " 51206,\n",
       " 51207,\n",
       " 51208,\n",
       " 51209,\n",
       " 51210,\n",
       " 51211,\n",
       " 51212,\n",
       " 51213,\n",
       " 51214,\n",
       " 51215,\n",
       " 51216,\n",
       " 51217,\n",
       " 51218,\n",
       " 51219,\n",
       " 51220,\n",
       " 51221,\n",
       " 51222,\n",
       " 51223,\n",
       " 51224,\n",
       " 51225,\n",
       " 51226,\n",
       " 51227,\n",
       " 51228,\n",
       " 51229,\n",
       " 51230,\n",
       " 51231,\n",
       " 51234,\n",
       " 51235,\n",
       " 51236,\n",
       " 51237,\n",
       " 51238,\n",
       " 51239,\n",
       " 51240,\n",
       " 51241,\n",
       " 51248,\n",
       " 51249,\n",
       " 51250,\n",
       " 51251,\n",
       " 51252,\n",
       " 51253,\n",
       " 51254,\n",
       " 51255,\n",
       " 51256,\n",
       " 51257,\n",
       " 51258,\n",
       " 51259,\n",
       " 51260,\n",
       " 51261,\n",
       " 51262,\n",
       " 51263,\n",
       " 51264,\n",
       " 51265,\n",
       " 51266,\n",
       " 51267,\n",
       " 51268,\n",
       " 51269,\n",
       " 51271,\n",
       " 51272,\n",
       " 51273,\n",
       " 51274,\n",
       " 51275,\n",
       " 51276,\n",
       " 51277,\n",
       " 51278,\n",
       " 51279,\n",
       " 51280,\n",
       " 51281,\n",
       " 51282,\n",
       " 51291,\n",
       " 51292,\n",
       " 51293,\n",
       " 51294,\n",
       " 51295,\n",
       " 51296,\n",
       " 51297,\n",
       " 51298,\n",
       " 51299,\n",
       " 51300,\n",
       " 51301,\n",
       " 51302,\n",
       " 51303,\n",
       " 51304,\n",
       " 51305,\n",
       " 51306,\n",
       " 51307,\n",
       " 51308,\n",
       " 51309,\n",
       " 51311,\n",
       " 51312,\n",
       " 51313,\n",
       " 51314,\n",
       " 51315,\n",
       " 51316,\n",
       " 51317,\n",
       " 51318,\n",
       " 51319,\n",
       " 51320,\n",
       " 51321,\n",
       " 51322,\n",
       " 51323,\n",
       " 51324,\n",
       " 51325,\n",
       " 51326,\n",
       " 51327,\n",
       " 51328,\n",
       " 51329,\n",
       " 51330,\n",
       " 51331,\n",
       " 51332,\n",
       " 51333,\n",
       " 51334,\n",
       " 51335,\n",
       " 51336,\n",
       " 51338,\n",
       " 51339,\n",
       " 51340,\n",
       " 51341,\n",
       " ...]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_list = subjects_refined[0:number_of_subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume correction\n",
    "* I have already extracted 4 volumes.\n",
    "* Now extract 120 - 4 = 116 volumes from each subject\n",
    "* So define vols = 114\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vols = vols - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vol_correct(sub_id, subid_vol_dict, vols):\n",
    "    sub_vols = subid_vol_dict[sub_id] - 4\n",
    "    if sub_vols > vols:\n",
    "        t_min = sub_vols - vols\n",
    "    elif sub_vols == vols:\n",
    "        t_min = 0\n",
    "    else:\n",
    "        raise Exception('Volumes of Sub ',sub_id,' less than desired!')\n",
    "    return int(t_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "volCorrect = Node(Function(function=vol_correct, input_names=['sub_id','subid_vol_dict','vols'],\n",
    "                                output_names=['t_min']), name='volCorrect')\n",
    "\n",
    "volCorrect.inputs.subid_vol_dict = subid_vol_dict\n",
    "volCorrect.inputs.vols = vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.chdir('/home1/varunk/results_again_again/temp/')\n",
    "# volCorrect.inputs.sub_id = 51456\n",
    "# res = volCorrect.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layout.get();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to fetch the filenames of a particular subject ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject_filenames(subject_id,brain_path,mask_path,atlas_path,tr_path,motion_params_path,func2std_mat_path,MNI3mm_path):\n",
    "    import re\n",
    "\n",
    "    for brain,mask,atlas,tr,motion_param,func2std_mat in zip(brain_path,mask_path,atlas_path,tr_path,motion_params_path,func2std_mat_path):\n",
    "#         sub_id_extracted = re.search('.+_subject_id_(\\d+)', brain).group(1)\n",
    "#         if subject_id == sub_id_extracted:\n",
    "        if str(subject_id) in brain:\n",
    "#             print(\"Files for subject \",subject_id,brain,mask,atlas,tr,motion_param)\n",
    "            return brain,mask,atlas,tr,motion_param,func2std_mat,MNI3mm_path\n",
    "        \n",
    "    print ('Unable to locate Subject: ',subject_id,'extracted: ',sub_id_extracted)\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a node\n",
    "getSubjectFilenames = Node(Function(function=get_subject_filenames, input_names=['subject_id','brain_path','mask_path','atlas_path','tr_path','motion_params_path','func2std_mat_path','MNI3mm_path'],\n",
    "                                output_names=['brain','mask','atlas','tr','motion_param','func2std_mat', 'MNI3mm_path']), name='getSubjectFilenames')\n",
    "\n",
    "\n",
    "getSubjectFilenames.inputs.brain_path = brain_path\n",
    "getSubjectFilenames.inputs.mask_path = mask_path\n",
    "getSubjectFilenames.inputs.atlas_path = atlas_path\n",
    "getSubjectFilenames.inputs.tr_path = tr_path\n",
    "getSubjectFilenames.inputs.motion_params_path = motion_params_path\n",
    "getSubjectFilenames.inputs.func2std_mat_path = func2std_mat_path\n",
    "getSubjectFilenames.inputs.MNI3mm_path = MNI3mm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# text = '/home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/atlas_resize_reg_directory/_subject_id_0050004/111std2func_xform/fullbrain_atlas_thr0-2mm_resample_flirt.nii'\n",
    "\n",
    "# try:\n",
    "#     found = re.search('.+_subject_id_(\\d+)', text).group(1)\n",
    "# except AttributeError:\n",
    "#     # AAA, ZZZ not found in the original string\n",
    "#     found = '' # apply your error handling\n",
    "\n",
    "# # found: 1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                  name=\"infosource\")\n",
    "\n",
    "infosource.iterables = [('subject_id',subject_list)]\n",
    "\n",
    "\n",
    "# ,'brain_path','mask_path','atlas_path','tr_path','motion_params_path'\n",
    "# infosource.brain_path = brain_path\n",
    "# infosource.mask_path = mask_path\n",
    "# infosource.atlas_path = atlas_path\n",
    "# infosource.tr_path = tr_path\n",
    "# infosource.motion_params_path = motion_params_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band Pass Filtering\n",
    "Let's do a band pass filtering on the data using the code from https://neurostars.org/t/bandpass-filtering-different-outputs-from-fsl-and-nipype-custom-function/824/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AFNI\n",
    "\n",
    "bandpass = Node(afni.Bandpass(highpass=0.01, lowpass=0.1, \n",
    "                         despike=False, no_detrend=True, notrans=True, \n",
    "                         outputtype='NIFTI_GZ'),name='bandpass')\n",
    "\n",
    "# bandpass = Node(afni.Bandpass(highpass=0.001, lowpass=0.01, \n",
    "#                          despike=False, no_detrend=True, notrans=True, \n",
    "#                          tr=2.0,outputtype='NIFTI_GZ'),name='bandpass')\n",
    "\n",
    "\n",
    "# bandpass.inputs.mask = MNI152_2mm.outputs.mask_file\n",
    "\n",
    "# highpass=0.008, lowpass=0.08, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing bandpass on the func data in subject's space\n",
    "\n",
    "# First comment out the bandpass.inputs.mask as it is in standard space.\n",
    "\n",
    "# subject_id = layout.get_subjects()[0] # gives the first subject's ID\n",
    "# func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])] \n",
    "# bandpass.inputs.in_file = func_file_path[0]\n",
    "# res = bandpass.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res.outputs.out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Highpass filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dBandpass.html\n",
    "# os.chdir('/home1/varunk/Autism-Connectome-Analysis-bids-related/')\n",
    "highpass = Node(afni.Bandpass(highpass=0.01, lowpass=99999, \n",
    "                         despike=False, no_detrend=True, notrans=True, \n",
    "                         outputtype='NIFTI_GZ'),name='highpass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test\n",
    "\n",
    "# subject_id = layout.get_subjects()[0] # gives the first subject's ID\n",
    "# func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])] \n",
    "# highpass.inputs.in_file = func_file_path[0]\n",
    "# res = highpass.run();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing \n",
    "### Using 6mm fwhm\n",
    "sigma = 6/2.3548 = 2.547987090198743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatialSmooth = Node(interface=ImageMaths(op_string='-s 2.5479',\n",
    "                                            suffix='_smoothed'),\n",
    "                   name='spatialSmooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performs Gram Schmidt Process\n",
    "https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orthogonalize(in_file, mask_file):\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    from os.path import join as opj\n",
    "    \n",
    "    def gram_schmidt(voxel_time_series, mean_vector):\n",
    "        numerator = np.dot(voxel_time_series,mean_vector)\n",
    "        dinominator = np.dot(mean_vector,mean_vector)\n",
    "        voxel_time_series_orthogonalized = voxel_time_series - (numerator/dinominator)*mean_vector\n",
    "        \n",
    "#         TO CONFIRM IF THE VECTORS ARE ORTHOGONAL\n",
    "#         sum_dot_prod = np.sum(np.dot(voxel_time_series_orthogonalized,mean_vector))\n",
    "        \n",
    "#         print('Sum of entries of orthogonalized vector = ',sum_dot_prod)\n",
    "        return voxel_time_series_orthogonalized\n",
    "    \n",
    "    \n",
    "    mask_data = nib.load(mask_file)\n",
    "    mask = mask_data.get_data()\n",
    "    \n",
    "    brain_data = nib.load(in_file)\n",
    "    brain = brain_data.get_data()\n",
    "\n",
    "    x_dim, y_dim, z_dim, t_dim = brain_data.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Find mean brain\n",
    "    \n",
    "    \n",
    "    mean_vector = np.zeros(t_dim)\n",
    "    \n",
    "    \n",
    "    num_brain_voxels = 0\n",
    "    \n",
    "    # Count the number of brain voxels\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            for k in range(z_dim):\n",
    "                if mask[i,j,k] == 1:\n",
    "                    mean_vector = mean_vector + brain[i,j,k,:]\n",
    "                    num_brain_voxels = num_brain_voxels + 1\n",
    "                    \n",
    "     \n",
    "    mean_vector = mean_vector / num_brain_voxels\n",
    "    \n",
    "    # Orthogonalize\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            for k in range(z_dim):\n",
    "                if mask[i,j,k] == 1:\n",
    "                    brain[i,j,k,:] = gram_schmidt(brain[i,j,k,:], mean_vector)\n",
    "                    \n",
    "    \n",
    "    \n",
    "    sub_id = in_file.split('/')[-1].split('.')[0].split('_')[0].split('-')[1]\n",
    "    \n",
    "    gsr_file_name = 'sub-' + sub_id + '_task-rest_run-1_bold.nii.gz'\n",
    "    \n",
    "#     gsr_file_name_nii = gsr_file_name + '.nii.gz'\n",
    "    \n",
    "    out_file = opj(os.getcwd(),gsr_file_name) # path\n",
    "    \n",
    "    brain_with_header = nib.Nifti1Image(brain, affine=brain_data.affine,header = brain_data.header)\n",
    "    nib.save(brain_with_header,gsr_file_name)\n",
    "    \n",
    "    return out_file\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globalSignalRemoval = Node(Function(function=orthogonalize, input_names=['in_file','mask_file'], \n",
    "                                  output_names=['out_file']), name='globalSignalRemoval' )\n",
    "# globalSignalRemoval.inputs.mask_file = mask_file\n",
    "# globalSignalRemoval.iterables = [('in_file',file_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM for regression of motion parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_residuals(subject,\n",
    "                   motion_file):\n",
    "    \"\"\"\n",
    "    Calculates residuals of nuisance regressors -motion parameters for every voxel for a subject using GLM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subject : string\n",
    "        Path of a subject's motion corrected nifti file.\n",
    "    motion_par_file : string\n",
    "        path of a subject's motion parameters\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    residual_file : string\n",
    "        Path of residual file in nifti format\n",
    "    \n",
    "    \"\"\"\n",
    "    import nibabel as nb\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from os.path import join as opj\n",
    "    nii = nb.load(subject)\n",
    "    data = nii.get_data().astype(np.float32)\n",
    "    global_mask = (data != 0).sum(-1) != 0\n",
    "\n",
    "    \n",
    "    # Check and define regressors which are provided from files\n",
    "    if motion_file is not None:\n",
    "        motion = np.genfromtxt(motion_file)\n",
    "        if motion.shape[0] != data.shape[3]:\n",
    "            raise ValueError('Motion parameters {0} do not match data '\n",
    "                             'timepoints {1}'.format(motion.shape[0], \n",
    "                                                     data.shape[3]))\n",
    "        if motion.size == 0:\n",
    "            raise ValueError('Motion signal file {0} is '\n",
    "                             'empty'.format(motion_file))\n",
    "\n",
    "    # Calculate regressors\n",
    "    regressor_map = {'constant' : np.ones((data.shape[3],1))}\n",
    "        \n",
    "    regressor_map['motion'] = motion\n",
    "        \n",
    "    \n",
    "    X = np.zeros((data.shape[3], 1))\n",
    "    \n",
    "    for rname, rval in regressor_map.items():\n",
    "        X = np.hstack((X, rval.reshape(rval.shape[0],-1)))\n",
    "\n",
    "    X = X[:,1:]\n",
    "    \n",
    "    if np.isnan(X).any() or np.isnan(X).any():\n",
    "        raise ValueError('Regressor file contains NaN')\n",
    "\n",
    "    Y = data[global_mask].T\n",
    "\n",
    "    try:\n",
    "        B = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        if \"Singular matrix\" in e:\n",
    "            raise Exception(\"Error details: {0}\\n\\nSingular matrix error: \"\n",
    "                            \"The nuisance regression configuration you \"\n",
    "                            \"selected may have been too stringent, and the \"\n",
    "                            \"regression could not be completed. Ensure your \"\n",
    "                            \"parameters are not too \"\n",
    "                            \"extreme.\\n\\n\".format(e))\n",
    "        else:\n",
    "            raise Exception(\"Error details: {0}\\n\\nSomething went wrong with \"\n",
    "                            \"nuisance regression.\\n\\n\".format(e))\n",
    "\n",
    "    Y_res = Y - X.dot(B)\n",
    "    \n",
    "    data[global_mask] = Y_res.T\n",
    "    \n",
    "    img = nb.Nifti1Image(data, header=nii.get_header(),\n",
    "                         affine=nii.get_affine())\n",
    "    \n",
    "    subject_name = subject.split('/')[-1].split('.')[0]\n",
    "    filename = subject_name + '_residual.nii.gz'\n",
    "    residual_file = os.path.join(os.getcwd(),filename )\n",
    "    img.to_filename(residual_file) # alt to nib.save\n",
    "    \n",
    "    return residual_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Node for above\n",
    "calc_residuals = Node(Function(function=calc_residuals, input_names=['subject','motion_file'],\n",
    "                                output_names=['residual_file']), name='calc_residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasink\n",
    "I needed to define the structure of what files are saved and where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create DataSink object\n",
    "dataSink = Node(DataSink(), name='datasink')\n",
    "\n",
    "# Name of the output folder\n",
    "dataSink.inputs.base_directory = opj(base_directory,fc_datasink_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the substitutions I looked the `datasink` folder where I was redirecting the output. I manually selected the part of file/folder name that I wanted to change and copied below to be substituted.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define substitution strings so that the data is similar to BIDS\n",
    "substitutions = [('_subject_id_', 'sub-')]\n",
    "\n",
    "# Feed the substitution strings to the DataSink node\n",
    "dataSink.inputs.substitutions = substitutions\n",
    "\n",
    "# ('_resample_brain_flirt.nii_brain', ''),\n",
    "# ('_roi_st_mcf_flirt.nii_brain_flirt', ''),\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home1/varunk/results_again_again'"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is a Join Node that collects the preprocessed file paths and saves them in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file_list_function(in_fc_map_brain_file):\n",
    "    # Imports\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from os.path import join as opj\n",
    "    \n",
    "    \n",
    "    file_list = np.asarray(in_fc_map_brain_file)\n",
    "    print('######################## File List ######################: \\n',file_list)\n",
    "\n",
    "    np.save('fc_map_brain_file_list',file_list)\n",
    "    file_name = 'fc_map_brain_file_list.npy'\n",
    "    out_fc_map_brain_file = opj(os.getcwd(),file_name) # path\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return out_fc_map_brain_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file_list = JoinNode(Function(function=save_file_list_function, input_names=['in_fc_map_brain_file'],\n",
    "                 output_names=['out_fc_map_brain_file']),\n",
    "                 joinsource=\"infosource\",\n",
    "                 joinfield=['in_fc_map_brain_file'],\n",
    "                 name=\"save_file_list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a FC node\n",
    "\n",
    "This node:\n",
    "1. Exracts the average time series of the brain ROI's using the atlas and stores \n",
    "    it as a matrix of size [ROIs x Volumes].\n",
    "2. Extracts the Voxel time series and stores it in matrix of size [Voxels x Volumes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Brains instead of FC matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saves the brains instead of FC matrix files\n",
    "def pear_coff(in_file, atlas_file, mask_file):\n",
    "    # code to find how many voxels are in the brain region using the mask\n",
    "    \n",
    "        # imports\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    from os.path import join as opj\n",
    "\n",
    "    mask_data = nib.load(mask_file)\n",
    "    mask = mask_data.get_data()\n",
    "\n",
    "    x_dim, y_dim, z_dim = mask_data.shape\n",
    "\n",
    "                    \n",
    "    atlasPath = atlas_file\n",
    "    # Read the atlas\n",
    "    atlasObject = nib.load(atlasPath)\n",
    "    atlas = atlasObject.get_data()\n",
    "    \n",
    "    num_ROIs = int((np.max(atlas) - np.min(atlas) ))\n",
    "\n",
    "\n",
    "    # Read the brain in_file\n",
    "\n",
    "    brain_data = nib.load(in_file)\n",
    "    brain = brain_data.get_data()\n",
    "\n",
    "    x_dim, y_dim, z_dim, num_volumes = brain.shape\n",
    "    \n",
    "    \n",
    "    num_brain_voxels = 0\n",
    "\n",
    "    x_dim, y_dim, z_dim = mask_data.shape\n",
    "\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            for k in range(z_dim):\n",
    "                if mask[i,j,k] == 1:\n",
    "                    num_brain_voxels = num_brain_voxels + 1\n",
    "    \n",
    "    # Initialize a matrix of ROI time series and voxel time series\n",
    "\n",
    "    ROI_matrix = np.zeros((num_ROIs, num_volumes))\n",
    "    voxel_matrix = np.zeros((num_brain_voxels, num_volumes))\n",
    "    \n",
    "    # Fill up the voxel_matrix \n",
    "\n",
    "    voxel_counter = 0\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            for k in range(z_dim):\n",
    "                if mask[i,j,k] == 1:\n",
    "                    voxel_matrix[voxel_counter,:] = brain[i,j,k,:] \n",
    "                    voxel_counter = voxel_counter + 1\n",
    "\n",
    "                    \n",
    "    # Fill up the ROI_matrix\n",
    "    # Keep track of number of voxels per ROI as well by using an array - num_voxels_in_ROI[]\n",
    "\n",
    "    num_voxels_in_ROI = np.zeros((num_ROIs,1)) # A column arrray containing number of voxels in each ROI\n",
    "\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            for k in range(z_dim):\n",
    "                label = int(atlas[i,j,k]) - 1\n",
    "                if label != -1:\n",
    "                    ROI_matrix[label,:] = np.add(ROI_matrix[label,:], brain[i,j,k,:])\n",
    "                    num_voxels_in_ROI[label,0] = num_voxels_in_ROI[label,0] + 1\n",
    "\n",
    "    ROI_matrix = np.divide(ROI_matrix,num_voxels_in_ROI) # Check if divide is working correctly\n",
    "\n",
    "    X, Y = ROI_matrix, voxel_matrix\n",
    "\n",
    "\n",
    "    # Subtract mean from X and Y\n",
    "\n",
    "    X = np.subtract(X, np.mean(X, axis=1, keepdims=True))\n",
    "    Y = np.subtract(Y, np.mean(Y, axis=1, keepdims=True))\n",
    "\n",
    "    temp1 = np.dot(X,Y.T)\n",
    "    temp2 = np.sqrt(np.sum(np.multiply(X,X), axis=1, keepdims=True))\n",
    "    temp3 = np.sqrt(np.sum(np.multiply(Y,Y), axis=1, keepdims=True))\n",
    "    temp4 = np.dot(temp2,temp3.T)\n",
    "    coff_matrix = np.divide(temp1, (temp4 + 1e-7))\n",
    "    \n",
    "    \n",
    "    # Check if any ROI is missing and replace the NAN values in coff_matrix by 0\n",
    "    if np.argwhere(np.isnan(coff_matrix)).shape[0] != 0:\n",
    "        print(\"Some ROIs are not present. Replacing NAN in coff matrix by 0\")\n",
    "        np.nan_to_num(coff_matrix, copy=False)\n",
    "\n",
    "    # TODO: when I have added 1e-7 in the dinominator, then why did I feel the need to replace NAN by zeros \n",
    "    sub_id = in_file.split('/')[-1].split('.')[0].split('_')[0].split('-')[1]\n",
    "    \n",
    "    \n",
    "    fc_file_name = sub_id + '_fc_map'\n",
    "    \n",
    "    print (\"Pear Matrix calculated for subject: \",sub_id)\n",
    "\n",
    "    roi_brain_matrix = coff_matrix\n",
    "    brain_file = in_file\n",
    "\n",
    "\n",
    "    x_dim, y_dim, z_dim, t_dim = brain.shape\n",
    "\n",
    "    (brain_data.header).set_data_shape([x_dim,y_dim,z_dim,num_ROIs])\n",
    "\n",
    "    brain_roi_tensor = np.zeros((brain_data.header.get_data_shape()))\n",
    "    \n",
    "    print(\"Creating brain for Subject-\",sub_id)\n",
    "    for roi in range(num_ROIs):\n",
    "        brain_voxel_counter = 0\n",
    "        for i in range(x_dim):\n",
    "            for j in range(y_dim):\n",
    "                for k in range(z_dim):\n",
    "                    if mask[i,j,k] == 1:\n",
    "                        brain_roi_tensor[i,j,k,roi] = roi_brain_matrix[roi,brain_voxel_counter]\n",
    "                        brain_voxel_counter = brain_voxel_counter + 1\n",
    "\n",
    "        \n",
    "        assert (brain_voxel_counter == len(roi_brain_matrix[roi,:])) \n",
    "    print(\"Created brain for Subject-\",sub_id)\n",
    "\n",
    "\n",
    "    path = os.getcwd()\n",
    "    fc_file_name = fc_file_name + '.nii.gz'\n",
    "    out_file = opj(path,fc_file_name)\n",
    "    \n",
    "    brain_with_header = nib.Nifti1Image(brain_roi_tensor, affine=brain_data.affine,header = brain_data.header)\n",
    "    nib.save(brain_with_header,out_file)\n",
    "    \n",
    "    \n",
    "    fc_map_brain_file = out_file\n",
    "    return fc_map_brain_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again Create the Node and set default values to paths\n",
    "\n",
    "pearcoff = Node(Function(function=pear_coff, input_names=['in_file','atlas_file','mask_file'],\n",
    "                                output_names=['fc_map_brain_file']), name='pearcoff')\n",
    "\n",
    "\n",
    "# output_names=['fc_map_brain_file']\n",
    "# pearcoff.inputs.atlas_file = atlasPath\n",
    "# pearcoff.inputs.num_brain_voxels = num_brain_voxels\n",
    "# pearcoff.inputs.mask_file = mask_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT:\n",
    "* The ROI 255 has been removed due to resampling. Therefore the FC maps will have nan at that row. So don't use that ROI :)\n",
    "* I came to know coz I keep getting this error: RuntimeWarning: invalid value encountered in true_divide\n",
    "* To debug it, I read the coff matrix and checked its diagnol to discover the nan value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ExtractROI - skip dummy scans\n",
    "extract = Node(ExtractROI(t_size=-1),\n",
    "               output_type='NIFTI',\n",
    "               name=\"extract\")\n",
    "\n",
    "# t_min=4,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Node for applying xformation matrix to functional data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func2std_xform = Node(FLIRT(output_type='NIFTI_GZ',\n",
    "                         apply_xfm=True), name=\"func2std_xform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pearcoff.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# motion_param_reg = [True, False]\n",
    "# global_signal_reg = [True, False]\n",
    "# band_pass_filt= [True, False]\n",
    "# for motion_param_regression, global_signal_regression, band_pass_filtering in zip(motion_param_reg, global_signal_reg, band_pass_filt):\n",
    "#     print (motion_param_regression, global_signal_regression, band_pass_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# itr = (list(itertools.product([0, 1], repeat=3)))\n",
    "\n",
    "# for motion_param_regression, global_signal_regression, band_pass_filtering in itr:\n",
    "#     print(motion_param_regression, global_signal_regression, band_pass_filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# itr = (list(itertools.product([0, 1], repeat=3)))\n",
    "\n",
    "# for motion_param_regression, global_signal_regression, band_pass_filtering in itr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the code to convert  the FC maps to brains instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination:  motionRegress1filt1global0smoothing1\n",
      "171229-19:59:16,984 workflow INFO:\n",
      "\t Generated workflow graph: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/graph.dot.png (graph2use=flat, simple_form=True).\n",
      "171229-19:59:18,602 workflow INFO:\n",
      "\t Workflow motionRegress1filt1global0smoothing1 settings: ['check', 'execution', 'logging']\n",
      "171229-19:59:18,627 workflow INFO:\n",
      "\t Running in parallel.\n",
      "171229-19:59:18,630 workflow INFO:\n",
      "\t Executing: volCorrect.a1 ID: 0\n",
      "171229-19:59:18,637 workflow INFO:\n",
      "\t [Job finished] jobname: volCorrect.a1 jobid: 0\n",
      "171229-19:59:18,638 workflow INFO:\n",
      "\t Executing: getSubjectFilenames.a1 ID: 1\n",
      "171229-19:59:18,642 workflow INFO:\n",
      "\t Executing: volCorrect.a0 ID: 8\n",
      "171229-19:59:18,662 workflow INFO:\n",
      "\t [Job finished] jobname: volCorrect.a0 jobid: 8\n",
      "171229-19:59:18,664 workflow INFO:\n",
      "\t Executing: getSubjectFilenames.a0 ID: 9\n",
      "171229-19:59:18,662 workflow INFO:\n",
      "\t Executing node getSubjectFilenames.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/getSubjectFilenames\n",
      "171229-19:59:18,676 workflow INFO:\n",
      "\t Executing node getSubjectFilenames.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/getSubjectFilenames\n",
      "171229-19:59:19,11 workflow INFO:\n",
      "\t [Job finished] jobname: getSubjectFilenames.a1 jobid: 1\n",
      "171229-19:59:19,13 workflow INFO:\n",
      "\t Executing: calc_residuals.a1 ID: 2\n",
      "171229-19:59:19,30 workflow INFO:\n",
      "\t Executing node calc_residuals.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/calc_residuals\n",
      "171229-19:59:19,109 workflow INFO:\n",
      "\t [Job finished] jobname: getSubjectFilenames.a0 jobid: 9\n",
      "171229-19:59:19,112 workflow INFO:\n",
      "\t Executing: calc_residuals.a0 ID: 10\n",
      "171229-19:59:19,129 workflow INFO:\n",
      "\t Executing node calc_residuals.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/calc_residuals\n",
      "171229-19:59:22,411 workflow INFO:\n",
      "\t [Job finished] jobname: calc_residuals.a1 jobid: 2\n",
      "171229-19:59:22,414 workflow INFO:\n",
      "\t Executing: extract.a1 ID: 3\n",
      "171229-19:59:22,418 workflow INFO:\n",
      "\t Executing node extract.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/extract\n",
      "171229-19:59:22,423 workflow INFO:\n",
      "\t [Job finished] jobname: calc_residuals.a0 jobid: 10\n",
      "171229-19:59:22,425 workflow INFO:\n",
      "\t Executing: extract.a0 ID: 11\n",
      "171229-19:59:22,426 workflow INFO:\n",
      "\t Running: fslroi /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/calc_residuals/sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual.nii.gz /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/extract/sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual_roi.nii.gz 80 -1\n",
      "171229-19:59:22,428 workflow INFO:\n",
      "\t Executing node extract.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/extract\n",
      "171229-19:59:22,434 workflow INFO:\n",
      "\t Running: fslroi /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/calc_residuals/sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual.nii.gz /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/extract/sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual_roi.nii.gz 80 -1\n",
      "171229-19:59:24,697 workflow INFO:\n",
      "\t [Job finished] jobname: extract.a1 jobid: 3\n",
      "171229-19:59:24,700 workflow INFO:\n",
      "\t Executing: bandpass.a1 ID: 4\n",
      "171229-19:59:24,733 workflow INFO:\n",
      "\t [Job finished] jobname: extract.a0 jobid: 11\n",
      "171229-19:59:24,734 workflow INFO:\n",
      "\t Executing node bandpass.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/bandpass\n",
      "171229-19:59:24,736 workflow INFO:\n",
      "\t Executing: bandpass.a0 ID: 12\n",
      "171229-19:59:24,741 workflow INFO:\n",
      "\t Running: 3dBandpass -prefix sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp.nii.gz -nodetrend -notrans -dt 1.500000 0.010000 0.100000 /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/bandpass/sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual_roi.nii.gz\n",
      "171229-19:59:24,745 workflow INFO:\n",
      "\t Executing node bandpass.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/bandpass\n",
      "171229-19:59:24,749 workflow INFO:\n",
      "\t Running: 3dBandpass -prefix sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp.nii.gz -nodetrend -notrans -dt 1.500000 0.010000 0.100000 /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/bandpass/sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual_roi.nii.gz\n",
      "171229-19:59:27,629 workflow INFO:\n",
      "\t [Job finished] jobname: bandpass.a0 jobid: 12\n",
      "171229-19:59:27,632 workflow INFO:\n",
      "\t Executing: spatialSmooth.a0 ID: 13\n",
      "171229-19:59:27,634 workflow INFO:\n",
      "\t Executing node spatialSmooth.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/spatialSmooth\n",
      "171229-19:59:27,638 workflow INFO:\n",
      "\t Running: fslmaths /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/bandpass/sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp.nii.gz -s 2.5479 /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/spatialSmooth/sub-0050002_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp_smoothed.nii.gz\n",
      "171229-19:59:27,655 workflow INFO:\n",
      "\t [Job finished] jobname: bandpass.a1 jobid: 4\n",
      "171229-19:59:27,658 workflow INFO:\n",
      "\t Executing: spatialSmooth.a1 ID: 5\n",
      "171229-19:59:27,660 workflow INFO:\n",
      "\t Executing node spatialSmooth.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/spatialSmooth\n",
      "171229-19:59:27,664 workflow INFO:\n",
      "\t Running: fslmaths /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/bandpass/sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp.nii.gz -s 2.5479 /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/spatialSmooth/sub-0050003_task-rest_run-1_bold_roi_st_mcf_residual_roi_bp_smoothed.nii.gz\n",
      "171229-19:59:32,292 workflow INFO:\n",
      "\t [Job finished] jobname: spatialSmooth.a1 jobid: 5\n",
      "171229-19:59:32,294 workflow INFO:\n",
      "\t Executing: pearcoff.a1 ID: 6\n",
      "171229-19:59:32,311 workflow INFO:\n",
      "\t Executing node pearcoff.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/pearcoff\n",
      "171229-19:59:32,429 workflow INFO:\n",
      "\t [Job finished] jobname: spatialSmooth.a0 jobid: 13\n",
      "171229-19:59:32,432 workflow INFO:\n",
      "\t Executing: pearcoff.a0 ID: 14\n",
      "171229-19:59:32,448 workflow INFO:\n",
      "\t Executing node pearcoff.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/pearcoff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "<string>:71: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some ROIs are not present. Replacing NAN in coff matrix by 0\n",
      "Pear Matrix calculated for subject:  0050003\n",
      "Creating brain for Subject- 0050003\n",
      "Some ROIs are not present. Replacing NAN in coff matrix by 0\n",
      "Pear Matrix calculated for subject:  0050002\n",
      "Creating brain for Subject- 0050002\n",
      "Created brain for Subject- 0050003\n",
      "Created brain for Subject- 0050002\n",
      "171229-20:00:17,324 workflow INFO:\n",
      "\t [Job finished] jobname: pearcoff.a1 jobid: 6\n",
      "171229-20:00:17,327 workflow INFO:\n",
      "\t Executing: func2std_xform.a1 ID: 7\n",
      "171229-20:00:17,343 workflow INFO:\n",
      "\t Executing node func2std_xform.a1 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/func2std_xform\n",
      "171229-20:00:17,348 workflow INFO:\n",
      "\t Running: flirt -in /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/pearcoff/0050003_fc_map.nii.gz -ref /home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/resample_mni/MNI152_T1_2mm_brain_resample.nii -out 0050003_fc_map_flirt.nii.gz -omat 0050003_fc_map_flirt.mat -applyxfm -init /home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/_subject_id_0050003/concat_xform/sub-0050003_task-rest_run-1_bold_roi_st_mcf_mean_bet_flirt_sub-0050003_T1w_brain_resample_flirt.mat\n",
      "171229-20:00:18,452 workflow INFO:\n",
      "\t [Job finished] jobname: pearcoff.a0 jobid: 14\n",
      "171229-20:00:18,454 workflow INFO:\n",
      "\t Executing: func2std_xform.a0 ID: 15\n",
      "171229-20:00:18,470 workflow INFO:\n",
      "\t Executing node func2std_xform.a0 in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/func2std_xform\n",
      "171229-20:00:18,475 workflow INFO:\n",
      "\t Running: flirt -in /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/pearcoff/0050002_fc_map.nii.gz -ref /home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/resample_mni/MNI152_T1_2mm_brain_resample.nii -out 0050002_fc_map_flirt.nii.gz -omat 0050002_fc_map_flirt.mat -applyxfm -init /home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/_subject_id_0050002/concat_xform/sub-0050002_task-rest_run-1_bold_roi_st_mcf_mean_bet_flirt_sub-0050002_T1w_brain_resample_flirt.mat\n",
      "171229-20:00:27,115 workflow INFO:\n",
      "\t [Job finished] jobname: func2std_xform.a1 jobid: 7\n",
      "171229-20:00:28,126 workflow INFO:\n",
      "\t [Job finished] jobname: func2std_xform.a0 jobid: 15\n",
      "171229-20:00:28,130 workflow INFO:\n",
      "\t Executing: save_file_list ID: 16\n",
      "171229-20:00:28,135 workflow INFO:\n",
      "\t Executing node save_file_list in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/save_file_list\n",
      "######################## File List ######################: \n",
      " [ '/home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50002/func2std_xform/0050002_fc_map_flirt.nii.gz'\n",
      " '/home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/_subject_id_50003/func2std_xform/0050003_fc_map_flirt.nii.gz']\n",
      "171229-20:00:28,149 workflow INFO:\n",
      "\t [Job finished] jobname: save_file_list jobid: 16\n",
      "171229-20:00:28,152 workflow INFO:\n",
      "\t Executing: datasink ID: 17\n",
      "171229-20:00:28,157 workflow INFO:\n",
      "\t Executing node datasink in dir: /home1/varunk/results_again_again/temp_fc/motionRegress1filt1global0smoothing1/datasink\n",
      "171229-20:00:28,172 workflow INFO:\n",
      "\t [Job finished] jobname: datasink jobid: 17\n"
     ]
    }
   ],
   "source": [
    "motion_param_regression = 1\n",
    "band_pass_filtering = 1\n",
    "global_signal_regression = 0\n",
    "smoothing = 1\n",
    "volcorrect = 1\n",
    "\n",
    "num_proc = 7\n",
    "\n",
    "combination = 'motionRegress' + str(int(motion_param_regression)) + 'filt' + \\\n",
    "              str(int(band_pass_filtering)) + 'global' + str(int(global_signal_regression)) + \\\n",
    "              'smoothing' + str(int(smoothing))\n",
    "        \n",
    "print(\"Combination: \",combination)\n",
    "\n",
    "base_dir = opj(base_directory,functional_connectivity_directory)\n",
    "# wf = Workflow(name=functional_connectivity_directory)\n",
    "wf = Workflow(name=combination)\n",
    "\n",
    "wf.base_dir = base_dir # Dir where all the outputs will be stored.\n",
    "\n",
    "wf.connect([(infosource , getSubjectFilenames, [('subject_id','subject_id')])])\n",
    "\n",
    "\n",
    "if motion_param_regression == 1 and global_signal_regression == 0 and band_pass_filtering == 1 and smoothing == 1 and volcorrect == 1: # 101\n",
    "\n",
    "    wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "    wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "    \n",
    "    wf.connect([( calc_residuals, extract, [('residual_file','in_file')])])\n",
    "    \n",
    "    wf.connect([(infosource, volCorrect, [('subject_id','sub_id')])])\n",
    "    \n",
    "    wf.connect([( volCorrect, extract, [('t_min','t_min')])])\n",
    "    \n",
    "    wf.connect([(extract, bandpass, [('roi_file','in_file')])])\n",
    "    \n",
    "    wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "    wf.connect([( bandpass, spatialSmooth, [('out_file','in_file')])])\n",
    "\n",
    "    wf.connect([( spatialSmooth, pearcoff, [('out_file','in_file')])])\n",
    "    \n",
    "    \n",
    "#     wf.connect([( extract, pearcoff, [('roi_file','in_file')])])\n",
    "    \n",
    "    # wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "    wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "    wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    wf.connect([(pearcoff, func2std_xform, [('fc_map_brain_file','in_file')])])\n",
    "    wf.connect([(getSubjectFilenames, func2std_xform, [('func2std_mat','in_matrix_file')])])\n",
    "    wf.connect([(getSubjectFilenames, func2std_xform, [('MNI3mm_path','reference')])])\n",
    "\n",
    "    #         -- send out file to save file list and then save the outputs\n",
    "\n",
    "\n",
    "\n",
    "    folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "    wf.connect([(func2std_xform,  save_file_list, [('out_file','in_fc_map_brain_file')])])\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "    wf.write_graph(graph2use='flat', format='png')\n",
    "#     from IPython.display import Image\n",
    "#     wf.write_graph(graph2use='exec', format='png', simple_form=True)\n",
    "    \n",
    "    wf.run('MultiProc', plugin_args={'n_procs': num_proc})\n",
    "#     file_name = opj(base_dir,combination,'graph_detailed.dot.png')\n",
    "#     Image(filename=file_name)\n",
    " \n",
    "elif motion_param_regression == 1 and global_signal_regression == 1 and band_pass_filtering == 1 and smoothing == 1: #111\n",
    "    wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "    wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "    \n",
    "    wf.connect([( calc_residuals, extract, [('residual_file','in_file')])])\n",
    "    \n",
    "    wf.connect([(infosource, volCorrect, [('subject_id','sub_id')])])\n",
    "    \n",
    "    wf.connect([( volCorrect, extract, [('t_min','t_min')])])\n",
    "    \n",
    "    wf.connect([(extract, globalSignalRemoval, [('roi_file','in_file')])])\n",
    "    \n",
    "\n",
    "#     wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "    wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "    wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "    wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "    wf.connect([( bandpass, spatialSmooth, [('out_file','in_file')])])\n",
    "\n",
    "    wf.connect([( spatialSmooth, pearcoff, [('out_file','in_file')])])\n",
    "\n",
    "    # wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "    wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "    wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    wf.connect([(pearcoff, func2std_xform, [('fc_map_brain_file','in_file')])])\n",
    "    wf.connect([(getSubjectFilenames, func2std_xform, [('func2std_mat','in_matrix_file')])])\n",
    "    wf.connect([(getSubjectFilenames, func2std_xform, [('MNI3mm_path','reference')])])\n",
    "\n",
    "#         -- send out file to save file list and then save the outputs\n",
    "\n",
    "\n",
    "\n",
    "    folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "    wf.connect([(func2std_xform,  save_file_list, [('out_file','in_fc_map_brain_file')])])\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "\n",
    "    #  wf.connect([(bandpass,  dataSink, [('out_file','motionRegress_filt_global.@out_file')])])\n",
    "\n",
    "\n",
    "    # if motion_param_regression == 1 and global_signal_regression == 1:\n",
    "    wf.write_graph(graph2use='flat', format='png')\n",
    "    wf.run('MultiProc', plugin_args={'n_procs': num_proc})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# motion_param_regression = 1\n",
    "# band_pass_filtering = 1\n",
    "# global_signal_regression = 1\n",
    "# smoothing = 1\n",
    "\n",
    "\n",
    "# combination = 'motionRegress' + str(int(motion_param_regression)) + 'filt' + \\\n",
    "#               str(int(band_pass_filtering)) + 'global' + str(int(global_signal_regression)) + \\\n",
    "#               'smoothing' + str(int(smoothing))\n",
    "        \n",
    "# print(\"Combination: \",combination)\n",
    "\n",
    "# wf = Workflow(name=functional_connectivity_directory)\n",
    "# wf.base_dir = base_directory # Dir where all the outputs will be stored(inside BETFlow folder).\n",
    "\n",
    "# wf.connect([(infosource , getSubjectFilenames, [('subject_id','subject_id')])])\n",
    "\n",
    "# if motion_param_regression == 1 and global_signal_regression == 1 and band_pass_filtering == 1 and smoothing = 1:\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "#         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "#         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "        \n",
    "#         wf.connect([( bandpass, spatialSmooth, [('out_file','in_file')])])\n",
    "        \n",
    "#         wf.connect([( spatialSmooth, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "#         wf.connect([(pearcoff, func2std_xform, [('fc_map_brain_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, func2std_xform, [('func2std_mat','in_matrix_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, func2std_xform, [('MNI3mm_path','reference')])])\n",
    "        \n",
    "# #         -- send out file to save file list and then save the outputs\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(func2std_xform,  save_file_list, [('out_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "\n",
    "#         #  wf.connect([(bandpass,  dataSink, [('out_file','motionRegress_filt_global.@out_file')])])\n",
    "\n",
    "\n",
    "#         # if motion_param_regression == 1 and global_signal_regression == 1:    \n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "        \n",
    "#         from IPython.display import Image\n",
    "#         wf.write_graph(graph2use='exec', format='png', simple_form=True)\n",
    "#         file_name = opj(base_directory,functional_connectivity_directory,'graph_detailed.dot.png')\n",
    "#         Image(filename=file_name)\n",
    "\n",
    "# elif motion_param_regression == 1 and global_signal_regression == 1 and band_pass_filtering == 0 and smoothing = 1: # 110\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "#         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "# #         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( globalSignalRemoval, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "\n",
    "\n",
    "# elif motion_param_regression == 1 and global_signal_regression == 0 and band_pass_filtering == 1  and smoothing = 1: # 101\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "# #         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "#         wf.connect([(calc_residuals, bandpass, [('residual_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})      \n",
    "\n",
    "# elif motion_param_regression == 1 and global_signal_regression == 0 and band_pass_filtering == 0 and smoothing = 1: # 100\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "# #         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "# #         wf.connect([(calc_residuals, bandpass, [('residual_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( calc_residuals, pearcoff, [('residual_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})   \n",
    "\n",
    "\n",
    "# elif motion_param_regression == 0 and global_signal_regression == 1 and band_pass_filtering == 1 and smoothing = 1: # 011\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "#         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})   \n",
    "\n",
    "\n",
    "\n",
    "# elif motion_param_regression == 0 and global_signal_regression == 1 and band_pass_filtering == 0 and smoothing = 1: # 010\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "# #         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( globalSignalRemoval, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "\n",
    "\n",
    "# elif motion_param_regression == 0 and global_signal_regression == 0 and band_pass_filtering == 1 and smoothing = 1: # 001\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('out_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "\n",
    "#         wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "\n",
    "# else:\n",
    "\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('brain','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "\n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "\n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "\n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results_again_again/temp_dataSink/pearcoff_motionRegress1filt1global1/fc_map_brain_file_list.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-531-a0b372e9a166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results_again_again/temp_dataSink/pearcoff_motionRegress1filt1global1/fc_map_brain_file_list.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results_again_again/temp_dataSink/pearcoff_motionRegress1filt1global1/fc_map_brain_file_list.npy'"
     ]
    }
   ],
   "source": [
    "X = np.load(\"../results_again_again/temp_dataSink/pearcoff_motionRegress1filt1global1/fc_map_brain_file_list.npy\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!nipypecli show crash-20171125-133018-varunk-pearcoff.a1-7b869482-76ad-4f55-af87-8b01e34e975c.pklz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.load('../results_again_again/fc_datasink/pearcoff_motionRegress1filt1global1/fc_map_brain_file_list.npy')\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# elif motion_param_regression == True and global_signal_regression == True and band_pass_filtering == False: # 110\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "#         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "# #         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( globalSignalRemoval, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "        \n",
    "        \n",
    "# elif motion_param_regression == True and global_signal_regression == False and band_pass_filtering == True: # 101\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "# #         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "#         wf.connect([(calc_residuals, bandpass, [('residual_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})      \n",
    "\n",
    "# elif motion_param_regression == True and global_signal_regression == False and band_pass_filtering == False: # 100\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "#         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "# #         wf.connect([(calc_residuals, globalSignalRemoval, [('residual_file','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "# #         wf.connect([(calc_residuals, bandpass, [('residual_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( calc_residuals, pearcoff, [('residual_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})   \n",
    "        \n",
    "        \n",
    "# elif motion_param_regression == False and global_signal_regression == True and band_pass_filtering == True: # 011\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "#         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "#         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( bandpass, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})   \n",
    "        \n",
    "        \n",
    "        \n",
    "# elif motion_param_regression == False and global_signal_regression == True and band_pass_filtering == False: # 010\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "#         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "# #         wf.connect([(globalSignalRemoval, bandpass, [('out_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( globalSignalRemoval, pearcoff, [('out_file','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "        \n",
    "        \n",
    "# elif motion_param_regression == False and global_signal_regression == False and band_pass_filtering == True: # 001\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('brain','subject')])])\n",
    "# #         wf.connect([(getSubjectFilenames, calc_residuals, [('motion_param', 'motion_file')])])\n",
    "        \n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('brain','in_file')] )])\n",
    "# #         wf.connect([(getSubjectFilenames, globalSignalRemoval, [('mask','mask_file')])])\n",
    "        \n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('out_file','in_file')])])\n",
    "# #         wf.connect([(getSubjectFilenames, bandpass, [('tr','tr')])])\n",
    "    \n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('brain','in_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('atlas','atlas_file')])])\n",
    "#         wf.connect([( getSubjectFilenames, pearcoff, [('mask','mask_file')])])\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folder_name = 'pearcoff_' + combination + '.@fc_map_brain_file'\n",
    "        \n",
    "        \n",
    "        \n",
    "#         wf.connect([(pearcoff,  save_file_list, [('fc_map_brain_file','in_fc_map_brain_file')])])\n",
    "\n",
    "        \n",
    "#         wf.connect([(save_file_list,  dataSink, [('out_fc_map_brain_file',folder_name)])])\n",
    "\n",
    "#         %time wf.run('MultiProc', plugin_args={'n_procs': 7})\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 111 -\n",
    "# 110 - \n",
    "# 101 - \n",
    "# 100\n",
    "# 011\n",
    "# 010\n",
    "# 001\n",
    "# 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "# from IPython.display import Image\n",
    "# wf.write_graph(graph2use='exec', format='png', simple_form=True)\n",
    "# file_name = opj(base_directory,functional_connectivity_directory,'graph_detailed.dot.png')\n",
    "# Image(filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def calc_residuals(subject,\n",
    "#                    motion_file):\n",
    "#     \"\"\"\n",
    "#     Calculates residuals of nuisance regressors -motion parameters for every voxel for a subject using GLM.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     subject : string\n",
    "#         Path of a subject's motion corrected nifti file.\n",
    "#     motion_par_file : string\n",
    "#         path of a subject's motion parameters\n",
    "    \n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     residual_file : string\n",
    "#         Path of residual file in nifti format\n",
    "    \n",
    "#     \"\"\"\n",
    "#     import nibabel as nb\n",
    "#     nii = nb.load(subject)\n",
    "#     data = nii.get_data().astype(np.float32)\n",
    "#     global_mask = (data != 0).sum(-1) != 0\n",
    "\n",
    "    \n",
    "#     # Check and define regressors which are provided from files\n",
    "#     if motion_file is not None:\n",
    "#         motion = np.genfromtxt(motion_file)\n",
    "#         if motion.shape[0] != data.shape[3]:\n",
    "#             raise ValueError('Motion parameters {0} do not match data '\n",
    "#                              'timepoints {1}'.format(motion.shape[0], \n",
    "#                                                      data.shape[3]))\n",
    "#         if motion.size == 0:\n",
    "#             raise ValueError('Motion signal file {0} is '\n",
    "#                              'empty'.format(motion_file))\n",
    "\n",
    "#     # Calculate regressors\n",
    "#     regressor_map = {'constant' : np.ones((data.shape[3],1))}\n",
    "        \n",
    "#     regressor_map['motion'] = motion\n",
    "        \n",
    "    \n",
    "#     X = np.zeros((data.shape[3], 1))\n",
    "    \n",
    "#     for rname, rval in regressor_map.items():\n",
    "#         X = np.hstack((X, rval.reshape(rval.shape[0],-1)))\n",
    "\n",
    "#     X = X[:,1:]\n",
    "    \n",
    "#     if np.isnan(X).any() or np.isnan(X).any():\n",
    "#         raise ValueError('Regressor file contains NaN')\n",
    "\n",
    "#     Y = data[global_mask].T\n",
    "\n",
    "#     try:\n",
    "#         B = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "#     except np.linalg.LinAlgError as e:\n",
    "#         if \"Singular matrix\" in e:\n",
    "#             raise Exception(\"Error details: {0}\\n\\nSingular matrix error: \"\n",
    "#                             \"The nuisance regression configuration you \"\n",
    "#                             \"selected may have been too stringent, and the \"\n",
    "#                             \"regression could not be completed. Ensure your \"\n",
    "#                             \"parameters are not too \"\n",
    "#                             \"extreme.\\n\\n\".format(e))\n",
    "#         else:\n",
    "#             raise Exception(\"Error details: {0}\\n\\nSomething went wrong with \"\n",
    "#                             \"nuisance regression.\\n\\n\".format(e))\n",
    "\n",
    "#     Y_res = Y - X.dot(B)\n",
    "    \n",
    "#     data[global_mask] = Y_res.T\n",
    "    \n",
    "#     img = nb.Nifti1Image(data, header=nii.get_header(),\n",
    "#                          affine=nii.get_affine())\n",
    "    \n",
    "#     subject_name = subject.split('/')[-1].split('.')[0]\n",
    "#     filename = subject_name + '_residual.nii.gz'\n",
    "#     residual_file = os.path.join(os.getcwd(),filename )\n",
    "#     img.to_filename(residual_file) # alt to nib.save\n",
    "    \n",
    "#     return residual_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Test\n",
    "# brain = '/home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/_subject_id_0050005/applyMask/sub-0050005_task-rest_run-1_bold_roi_st_mcf.nii_brain.nii.gz'\n",
    "# mask = '/home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/_subject_id_0050005/meanfuncmask/sub-0050005_task-rest_run-1_bold_roi_st_mcf_mean_brain_mask.nii.gz'\n",
    "# atlas = '/home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/coreg_reg/atlas_resize_reg_directory/_subject_id_0050005/std2func_xform/fullbrain_atlas_thr0-2mm_resample_flirt.nii '\n",
    "# # tr = 1.5\n",
    "# par_file = '/home1/varunk/results_again_again/ABIDE1_Preprocess/motion_correction_bet/_subject_id_0050005/mcflirt/sub-0050005_task-rest_run-1_bold_roi_st_mcf.nii.par'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calc_residuals(brain,par_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# motion = np.genfromtxt(par_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('../results_again_again/fc_datasink/pearcoff_motionRegress0filt0global1/fc_map_brain_file_list.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
